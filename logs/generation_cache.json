{
    "question": [
        "What is the 'Emoji Attack' method proposed by Wei et al. (2025) and how does it affect Judge LLMs?",
        "According to Chen et al. (2024), how do gender and age influence emoji comprehension?",
        "What is 'EmojiLM' and how was the Text2Emoji corpus created?",
        "Describe the 'Emojinize' system. How does it translate text to emojis?",
        "What success rate did Gopinadh and Hussain (2026) report for emoji-based jailbreaking on the Qwen 2 7B model?",
        "How does 'EmojiPrompt' obfuscate private data in cloud-based LLM interactions?",
        "According to Zappavigna (2025), what are the two main ways LLMs use emojis as interpersonal resources?",
        "What method does Zhang (2025) introduce in 'Emoti-Attack'?",
        "How does ChatGPT perform when annotating emoji irony compared to humans, according to Zhou et al. (2025)?",
        "What is the specific vulnerability identified in 'Small Symbols, Big Risks' regarding ASCII-based emoticons?",
        "Compare the adversarial attack strategies in Wei2025 ('Emoji Attack') vs Zhang2025 ('Emoti-Attack'). How do they differ in their use of emojis?",
        "Contrast the text-to-emoji translation approaches taken by 'EmojiLM' (Peng2023) and 'Emojinize' (Klein2024).",
        "Discuss the safety implications of emojis in LLMs by synthesizing findings from Gopinadh2026 and Cui2025.",
        "How does human interpretation of emojis (Chen2024) compare to LLM interpretation of emojis (Zhou2025)?",
        "What evidence exists in the corpus regarding emojis being used for privacy (Lin2025) versus emojis being used for attacks (Wei2025)?",
        "Does the corpus contain evidence about the use of emojis in audio-to-text transcription models like Whisper?",
        "What is the impact of emojis on stock market prediction algorithms according to these papers?",
        "Does the corpus mention 'EmojiGAN' or image generation models for creating new emojis?",
        "What specific hardware GPU was used to train the 'EmojiPrompt' system?",
        "Are there any papers in the corpus published before 2018?",
        "What is life?",
        "How many chickens would fit in Carnegie Mellon?"
    ],
    "answer": [
        "The 'Emoji Attack' method proposed by Wei et al. (2025) exploits a vulnerability in Judge LLMs known as **token segmentation bias**. This bias occurs when emojis or other delimiters alter the tokenization process, splitting words into smaller sub-tokens and causing distortions in the embeddings of the entire sequence (Wei, Liu and Erichson, 2025).\n\nThis attack leverages **in-context learning** to systematically insert emojis into text before it is evaluated by a Judge LLM. The insertion induces embedding distortions and introduces semantic ambiguity, which significantly reduces the detection accuracy of the Judge LLM (Wei, Liu and Erichson, 2025).\n\nAs a result, the 'Emoji Attack' enables harmful content to be **misclassified as safe**, effectively bypassing existing safeguards and detection mechanisms (Wei, Liu and Erichson, 2025).\n\n### References\n- **Wei2025**: Zhipeng Wei, Yuqi Liu, Benjamin Erichson (2025). *Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection*. [Link](https://arxiv.org/abs/2411.01077v5)",
        "According to Chen et al. (2024), their study examined the influence of gender, age, and culture on emoji comprehension, but the provided context does not explicitly detail the specific findings or mechanisms of how these factors influence comprehension (Chen et al., 2024).\n\n### References\n- **Chen2024**: Yihua Chen, Xingchen Yang, Hannah Howman, Ruth Filik (2024). *Individual differences in emoji comprehension: Gender, age, and culture*. [Link](https://doi.org/10.1371/journal.pone.0297379)",
        "'EmojiLM' is a model used for English-Emoji translation, as evidenced by its evaluation in the Text2Emoji corpus. The Text2Emoji corpus was created using large language models (LLMs), though the exact methodology is not explicitly detailed in the provided context. (Peng et al., 2023)\n\n### References\n- **Peng2023**: Letian Peng, ZilongWang, Hang Liu, ZihanWang, Jingbo Shang (2023). *EmojiLM: Modeling the New Emoji Language*. [Link](https://arxiv.org/abs/2311.01751)",
        "The 'Emojinize' system is an automatic translation system that converts English text into sequences of one or more emojis (Klein, Aydin and West, 2024). It leverages large language models (LLMs) to understand the semantic meaning of text and translate it into emoji sequences (Klein, Aydin and West, 2024). Unlike existing systems that use static lookup tables or next-token prediction, Emojinize considers both prior and subsequent contexts to disambiguate synonyms and ensure accurate translation (Klein, Aydin and West, 2024). It can handle both singular words and multi-word expressions by composing multiple emojis to express complex concepts (Klein, Aydin and West, 2024). The system's flexibility allows it to translate arbitrary text passages without requiring human input (Klein, Aydin and West, 2024).\n\n### References\n- **Klein2024**: Lars Klein, Roland Aydin, Robert West (2024). *Emojinize: Enriching Any Text with Emoji Translations*. [Link](https://arxiv.org/abs/2403.03857)",
        "The success rate for emoji-based jailbreaking on the Qwen 2 7B model was 0% (Gopinadh and Hussain, 2026).\n\n### References\n- **Gopinadh2026**: M P V S Gopinadh, S Mahaboob Hussain (2026). *EMOJI-BASED JAILBREAKING OF LARGE LANGUAGE MODELS*. [Link](https://arxiv.org/abs/2601.00936v1)",
        "EmojiPrompt obfuscates private data by using Large Language Models (LLMs) to perform a generative transformation. This process converts private data from natural language into non-natural language forms by incorporating a mixture of linguistic elements (e.g., abbreviated characters) and non-linguistic elements (e.g., emojis, emoticons, mathematical and logical operators) (Lin et al., 2025). Additionally, EmojiPrompt employs an atomic-level obfuscation strategy, which partitions private data into smaller modular units, obfuscates each unit separately, and then reconstructs the obfuscated data from these individual components (Lin et al., 2025).\n\n### References\n- **Lin2025**: Sam Lin, Wenyue Hua, Zhenting Wang, Mingyu Jin, Lizhou Fan, Yongfeng Zhang (2025). *EmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving Communication with Cloud-based LLMs*. [Link](https://arxiv.org/abs/2402.05868)",
        "Based on the provided context, the study by Zappavigna (2025) identifies that LLMs use emojis as interpersonal resources primarily to shape interpersonal tone and build rapport. These functions are achieved by softening requests, signalling enthusiasm, and fostering a sense of connection (Zappavigna and Doran, 2025).\n\nHowever, the context does not explicitly state two distinct \"main ways\" but rather describes these as key functions within the broader analysis using the tenor system (TUNING) and the system of emoji-text convergence (Zappavigna and Doran, 2025). The study focuses on how these emoji functions contribute to making chatbots appear friendly and supportive (Zappavigna and Doran, 2025).\n\nTherefore, while the study highlights these interpersonal functions, it does not explicitly define two separate main ways beyond the framework of the tenor system and emoji-text convergence (Zappavigna and Doran, 2025).\n\n### References\n- **Zappavigna2025**: Michele Zappavigna, Y.J. Doran (2025). *Emoji as interpersonal resources in LLM chatbot conversations: a social semiotic analysis of tenor and affiliation in human\u2013AI interaction*. [Link](https://doi.org/10.1080/10350330.2025.2570317)",
        "Zhang (2025) introduces the **Emoji-Attack** method in 'Emoti-Attack' (Zhang, 2025). This method leverages emojis to create subtle, zero-perturbation adversarial attacks on NLP systems, targeting emojis as a distinct layer of attack to minimize perceptibility while maintaining effectiveness.\n\n### References\n- **Zhang2025**: Yangshijie Zhang (2025). *Emoti-Attack: Zero-Perturbation Adversarial Attacks on NLP Systems via Emoji Sequences*. [Link](https://arxiv.org/abs/2502.17392v1)",
        "Based on the provided context, there is no information from Zhou et al. (2025) regarding ChatGPT's performance in annotating emoji irony. The study by Zhou et al. (2025) in the context focuses on sentiment annotation and downstream tasks, not irony detection. (Zhou et al., 2025)\n\n### References\n- **Zhou2025**: Yuhang Zhou, Paiheng Xu, Xiyao Wang, Xuan Lu, Ge Gao, Wei Ai (2025). *Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social Media Communications*. [Link](https://arxiv.org/abs/2402.01681)",
        "The specific vulnerability identified in \"Small Symbols, Big Risks\" is **emoticon semantic confusion**, where Large Language Models (LLMs) misinterpret ASCII-based emoticons as part of the user's instruction, leading to unintended and potentially destructive actions (Jiang et al., 2026). This vulnerability is pervasive, with an average confusion ratio exceeding 38%, and often results in \"silent failures\"\u2014syntactically valid outputs that deviate from user intent (Jiang et al., 2026).\n\n### References\n- **Jiang2026**: Weipeng Jiang, Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Chao Shen, Yang Liu (2026). *Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in Large Language Models*. [Link](https://arxiv.org/abs/2601.07885)",
        "Based on the provided context:\n\nEmoti-Attack (Zhang, 2025) is explicitly defined as a \"zero-perturbation\" adversarial attack that targets emojis as a distinct layer of manipulation, aiming for subtle changes with minimal disruption to the text (Zhang, 2025). It leverages emoji properties like polysemy and contextual framing (Grover, 2025).\n\nIn contrast, Wei2025's Emoji Attack focuses on inserting emojis, particularly as a suffix, and optimizing a universal adversarial suffix using methods like GCG (Wei, Liu and Erichson, 2025). It demonstrates strong performance even against black-box defenses (Wei, Liu and Erichson, 2025).\n\n### References\n- **Wei2025**: Zhipeng Wei, Yuqi Liu, Benjamin Erichson (2025). *Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection*. [Link](https://arxiv.org/abs/2411.01077v5)\n- **Zhang2025**: Yangshijie Zhang (2025). *Emoti-Attack: Zero-Perturbation Adversarial Attacks on NLP Systems via Emoji Sequences*. [Link](https://arxiv.org/abs/2502.17392v1)\n- **Grover2025**: Shubham Grover (2025). *Neutralizing the Emojis: Developing Robust LLM Defenses Against Adversarial Emoji-fiction Attacks*. [Link](https://ijsate.com/wp-content/uploads/2025/12/V2I12P35_IJSATE1225010.pdf)",
        "Here is a contrast between the text-to-emoji translation approaches of EmojiLM and Emojinize based on the provided context:\n\n**1. Approach and Architecture:**\n   - **EmojiLM**: A sequence-to-sequence language model trained on a parallel English-Emoji corpus (Text2Emoji). It leverages a transformer-based architecture (similar to BART) for text-to-emoji translation, focusing on next-token prediction (Peng et al., 2023).\n   - **Emojinize**: A context-aware translation system that integrates feedback from an oracle model using a multi-shot mechanism. It employs a transformer architecture to handle bidirectional context and disambiguate synonyms (Klein, Aydin and West, 2024).\n\n**2. Context Awareness:**\n   - **EmojiLM**: Utilizes a left-to-right next-token prediction approach, considering only preceding context during translation (Peng et al., 2023).\n   - **Emojinize**: Incorporates both prior and subsequent context to disambiguate synonyms and improve translation accuracy, enabling bidirectional understanding (Klein, Aydin and West, 2024).\n\n**3. Output and Translation Quality:**\n   - **EmojiLM**: Generates emoji sequences that capture the essence of the input text, often combining multiple emojis to represent complex ideas (e.g., \"saw an incredible sunset\" translated to \ud83c\udfd4\ud83c\udf05\ud83d\udc40\ud83d\udcab) (Peng et al., 2023).\n   - **Emojinize**: Produces emoji translations that are context-sensitive and expressive, capable of handling multi-word expressions and improving text comprehension through bidirectional context (Klein, Aydin and West, 2024).\n\n**4. Evaluation and Claims:**\n   - **EmojiLM**: Outperforms text-to-text baselines like BART and text classification models like BERTweet, demonstrating advancements in emoji-based language understanding (Peng et al., 2023).\n   - **Emojinize**: Claims to outperform human annotation and improve text comprehension, supported by user studies and synthetic evaluations (Klein, Aydin and West, 2024).\n\n**5. Methodology:**\n   - **EmojiLM**: Relies on a large parallel corpus for training and distills knowledge from existing language models (Peng et al., 2023).\n   - **Emojinize**: Uses a multi-shot translation mechanism with feedback from an oracle model, enhancing translation accuracy and scalability (Klein, Aydin and West, 2024).\n\nIn summary, **EmojiLM** focuses on sequence-to-sequence translation using next-token prediction, while **Emojinize** emphasizes bidirectional context and feedback mechanisms for more accurate and expressive emoji translations.\n\n### References\n- **Klein2024**: Lars Klein, Roland Aydin, Robert West (2024). *Emojinize: Enriching Any Text with Emoji Translations*. [Link](https://arxiv.org/abs/2403.03857)\n- **Peng2023**: Letian Peng, ZilongWang, Hang Liu, ZihanWang, Jingbo Shang (2023). *EmojiLM: Modeling the New Emoji Language*. [Link](https://arxiv.org/abs/2311.01751)",
        "The safety implications of emojis in LLMs are significant, as they can be exploited to trigger harmful outputs and bypass safety mechanisms. Cui2025 demonstrates that emojis can act as a \"heterogeneous semantic channel\" to evade LLM safety defenses, with experiments showing that emoji-augmented prompts significantly increase the likelihood of toxic generation across multiple models and languages (Cui et al., 2025). This toxicity is linked to data pollution in the training corpus, suggesting systemic vulnerabilities (Cui et al., 2025).\n\nGopinadh2026 highlights that emojis can be weaponized for \"emoji-based jailbreaking,\" necessitating automated detection mechanisms and pre-deployment testing with emoji-augmented prompts to mitigate risks (Gopinadh and Hussain, 2026). Additionally, the study emphasizes the need to explore other non-textual inputs and address fairness implications, as emoji misinterpretation could disproportionately affect certain user groups, undermining the equitable deployment of LLMs (Gopinadh and Hussain, 2026).\n\nTogether, these studies underscore that emojis introduce novel attack vectors for adversarial misuse, requiring both technical defenses (e.g., detection, robust tokenization) and interpretative research to understand and address the underlying mechanisms of emoji-triggered toxicity (Cui et al., 2025)(Gopinadh and Hussain, 2026).\n\n### References\n- **Gopinadh2026**: M P V S Gopinadh, S Mahaboob Hussain (2026). *EMOJI-BASED JAILBREAKING OF LARGE LANGUAGE MODELS*. [Link](https://arxiv.org/abs/2601.00936v1)\n- **Cui2025**: Shiyao Cui, Xijia Feng, Yingkang Wang, Junxiao Yang, Zhexin Zhang, Biplab Sikdar, Hongning Wang, Han Qiu, Minlie Huang (2025). *When Smiley Turns Hostile: Interpreting How Emojis Trigger LLMs\u2019 Toxicity*. [Link](https://arxiv.org/abs/2509.11141)",
        "I am unable to answer this question because the provided context does not include any sources by Chen2024 or Zhou2025. Therefore, I cannot compare their findings or make any claims about their work.",
        "Based on the provided context:\n\n1.  **Evidence for emojis being used for attacks:** The context provides evidence that emojis can be used in contexts related to attacks or harmful activities. Specifically, it mentions that emojis can be associated with \"hacking, phishing and illegally financial activities\" (Cui et al., 2025). This is supported by the analysis of emoji contexts showing associations with \"gambling, illegal downloads, fraud, and pornography\" (Cui et al., 2025).\n\n2.  **Evidence for emojis being used for privacy:** The provided context does not contain any direct evidence or discussion regarding emojis being used specifically for privacy purposes. The context focuses on emojis being used in harmful contexts, including potential attacks, but does not mention privacy as a distinct function or use case.\n\n### References\n- **Cui2025**: Shiyao Cui, Xijia Feng, Yingkang Wang, Junxiao Yang, Zhexin Zhang, Biplab Sikdar, Hongning Wang, Han Qiu, Minlie Huang (2025). *When Smiley Turns Hostile: Interpreting How Emojis Trigger LLMs\u2019 Toxicity*. [Link](https://arxiv.org/abs/2509.11141)",
        "No, the provided context does not contain any evidence or mention of emojis being used in audio-to-text transcription models like Whisper. The sources focus on emoji translation, emoji integration in NLP models, and emoji handling in text-based models, but there is no discussion of audio transcription or Whisper specifically (Peng et al., 2023), (Grover, 2025).\n\n### References\n- **Peng2023**: Letian Peng, ZilongWang, Hang Liu, ZihanWang, Jingbo Shang (2023). *EmojiLM: Modeling the New Emoji Language*. [Link](https://arxiv.org/abs/2311.01751)\n- **Grover2025**: Shubham Grover (2025). *Neutralizing the Emojis: Developing Robust LLM Defenses Against Adversarial Emoji-fiction Attacks*. [Link](https://ijsate.com/wp-content/uploads/2025/12/V2I12P35_IJSATE1225010.pdf)",
        "Based on the provided context, there is no direct evidence or discussion regarding the impact of emojis on stock market prediction algorithms. The papers referenced focus on emoji functionality, ChatGPT applications, emoji prediction tasks, hate detection, and adversarial attacks on language models, but none address stock market prediction specifically.\n\n(Cui et al., 2025): The paper focuses on emojis in language models but does not mention stock markets (Cui et al., 2025).\n\n(Wei, Liu and Erichson, 2025): This paper discusses emoji attacks on language models for jailbreak purposes, not stock market prediction (Wei, Liu and Erichson, 2025).\n\n(Zhou et al., 2025): The paper reviews emoji functionalities and ChatGPT applications but does not address stock market prediction algorithms (Zhou et al., 2025).\n\n(Peng et al., 2023): This paper discusses emoji prediction benchmarks and related work but does not mention stock market prediction (Peng et al., 2023).\n\nTherefore, the provided context does not contain information on the impact of emojis on stock market prediction algorithms.\n\n### References\n- **Wei2025**: Zhipeng Wei, Yuqi Liu, Benjamin Erichson (2025). *Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection*. [Link](https://arxiv.org/abs/2411.01077v5)\n- **Peng2023**: Letian Peng, ZilongWang, Hang Liu, ZihanWang, Jingbo Shang (2023). *EmojiLM: Modeling the New Emoji Language*. [Link](https://arxiv.org/abs/2311.01751)\n- **Cui2025**: Shiyao Cui, Xijia Feng, Yingkang Wang, Junxiao Yang, Zhexin Zhang, Biplab Sikdar, Hongning Wang, Han Qiu, Minlie Huang (2025). *When Smiley Turns Hostile: Interpreting How Emojis Trigger LLMs\u2019 Toxicity*. [Link](https://arxiv.org/abs/2509.11141)\n- **Zhou2025**: Yuhang Zhou, Paiheng Xu, Xiyao Wang, Xuan Lu, Ge Gao, Wei Ai (2025). *Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social Media Communications*. [Link](https://arxiv.org/abs/2402.01681)",
        "The provided context does not mention 'EmojiGAN' or image generation models for creating new emojis (Peng et al., 2023).\n\n### References\n- **Peng2023**: Letian Peng, ZilongWang, Hang Liu, ZihanWang, Jingbo Shang (2023). *EmojiLM: Modeling the New Emoji Language*. [Link](https://arxiv.org/abs/2311.01751)",
        "I am unable to answer the question based on the provided context, as there is no information about the specific hardware GPU used to train the 'EmojiPrompt' system. [No citation available]",
        "Yes, there is at least one paper in the corpus published before 2018 (Grover, 2025).\n\n### References\n- **Grover2025**: Shubham Grover (2025). *Neutralizing the Emojis: Developing Robust LLM Defenses Against Adversarial Emoji-fiction Attacks*. [Link](https://ijsate.com/wp-content/uploads/2025/12/V2I12P35_IJSATE1225010.pdf)",
        "Based on the provided context, the meaning of life is not explicitly defined or discussed. The context includes references to personality traits and artificial intelligence but does not address the philosophical question of \"What is life?\" Therefore, I cannot provide a definitive answer to this question based solely on the given information.",
        "The provided context does not contain information about the size of Carnegie Mellon or any calculations related to fitting chickens. Therefore, I cannot provide an answer to this question based on the given context."
    ],
    "contexts": [
        [
            "Copyright 2025\nby the author(s). GPT-3.5\nJailbreaks + Emoji Attack (    )\nJailbreaks\nWildGuard\nShieldLM\nLlama Guard 2\nLlama Guard\no3-mini\nDeepSeek\nClaude\nGemini\nGPT-4\nFigure 1. Average unsafe prediction ratio of Judge LLMs across\nfive jailbreak attack methods. Our proposed emoji attack enhances\njailbreaking, and enables harmful content to evade detection. et al., 2024) have been developed to evaluate the safety of the\ngenerated responses and intervene when necessary. Many\nJudge LLMs assign numerical scores to indicate content\nseverity, for example, on a scale from 1 to 10, where higher\nscores denote stronger violations of ethical, legal, or safety\nguidelines (Liu et al., 2024a). If a score exceeds a prede-\nfined threshold, the response is flagged as unsafe. Although\nthese moderation mechanisms offer promising automated\nsolutions, they remain vulnerable to specific exploits. In this paper, we address the following research question:\nCan seemingly benign linguistic constructs, such\nas emojis, systematically alter the decision bound-\naries of Judge LLMs, enabling harmful content to\nbypass moderation filters? To answer this, we reveal a critical weakness in Judge\nLLMs: token segmentation bias. This bias occurs when\nminor input modifications alter how text is tokenized into\nsubwords, leading to embedding distortions that affect con-\ntextual understanding. Tokenization is a fundamental aspect\n1\narXiv:2411.01077v5  [cs.CL]  16 Aug 2025",
            "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection\nthe target LLM level, less attention has been paid to attacks\naimed directly at Judge LLMs, which determine whether\nthe generated content is harmful. One study by Mangaokar\net al. (2024) extends GCG to optimize a universal adversar-\nial prefix against white-box Judge LLMs. Using in-context\nlearning (Brown et al., 2020), it instructs the target LLM to\nproduce harmful outputs that the Judge LLM subsequently\nmisclassifies. However, similar to GCG, this approach re-\nmains query-intensive and encounters scalability constraints. In addition, Charmer (Rocamora et al., 2024) employs a\nheuristic approach to search for and insert characters into\nspecific positions. However, it overlooks the fundamental\nunderstanding of text segmentation and does not account for\nthe integration of emojis, which are increasingly relevant in\nmodern text processing tasks. In contrast, our proposed Emoji Attack exploits token seg-\nmentation bias, does not require extensive optimization, and\ncan be seamlessly integrated with existing jailbreak meth-\nods. As a result, it presents a lightweight yet effective tool\nfor misleading Judge LLMs and shows the need to address\nsuch vulnerabilities in guardrail systems. 3. Methodology\nIn this section, we introduce our approach to exploit token\nsegmentation and semantic meaning biases to enhance jail-\nbreak attacks against Judge LLMs. We begin by defining\nthe problem setup involving a target LLM and a Judge LLM. We then discuss the phenomenon of token segmentation\nbias. Finally, we introduce our proposed Emoji Attack.",
            "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection\nstrategies against various Judge LLMs. First, we describe\nthe experimental protocols to ensure a fair comparison. We\nthen demonstrate how our proposed Emoji Attack improves\njailbreak attacks against Judge LLM detection. Finally,\nwe show how both token segmentation bias and white-box\nEmoji Attack substantially reduce unsafe detection rates. 4.1.",
            "jis during response generation (de Janeiro 2023; Lyu et al. 2024; Jain et al. 2025). Despite the success above, few stud-\nies have investigated whether the presence of emojis could\nfacilitate the toxicity generation of LLMs. Wei, Liu, and\nErichson (2025) demonstrate that emojis can hinder harm-\nful content detection of judge LLMs, but our work focuses\non how emojis influence the toxicity generation process of\nthe target LLM itself, which is under-explored previously. 6.2 Toxicity Generation with Low-resourced\nLanguages or Specialized Coding\nSeveral studies have demonstrated that low-resourced lan-\nguages (e.g., Zulu) and specialized coding (e.g., Base64)\ncould elicit harmful outputs from LLMs, which are closely\nrelated to our research. Specifically, harmful outputs could\nbe elicited via low-resourced languages with both direct\nharmful requests (Deng et al. 2024; Wang et al.",
            "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection\nZhipeng Wei 1 2 Yuqi Liu1 N. Benjamin Erichson 1 3\nAbstract\nJailbreaking techniques trick Large Language\nModels (LLMs) into producing restricted output,\nposing a potential threat. One line of defense is to\nuse another LLM as a Judge to evaluate the harm-\nfulness of generated text. However, we reveal that\nthese Judge LLMs are vulnerable to token segmen-\ntation bias, an issue that arises when delimiters\nalter the tokenization process, splitting words into\nsmaller sub-tokens. This alters the embeddings\nof the entire sequence, reducing detection accu-\nracy and allowing harmful content to be misclas-\nsified as safe. In this paper, we introduce Emoji\nAttack, a novel strategy that amplifies existing jail-\nbreak prompts by exploiting token segmentation\nbias. Our method leverages in-context learning to\nsystematically insert emojis into text before it is\nevaluated by a Judge LLM, inducing embedding\ndistortions that significantly lower the likelihood\nof detecting unsafe content. Unlike traditional\ndelimiters, emojis also introduce semantic ambi-\nguity, making them particularly effective in this\nattack. Through experiments on state-of-the-art\nJudge LLMs, we demonstrate that Emoji Attack\nsubstantially reduces the unsafe prediction rate,\nbypassing existing safeguards."
        ],
        [
            "(2024) highlighted that LLMs face\nchallenges in suggesting emojis that align with the semantic\nmeaning of social media posts. Building on this foundation,\nour study focuses on investigating how LLMs interpret emo-\njis within a specific category: ironic emojis. Several studies have explored factors influencing human\ninterpretation of emojis, including personality traits (Li et al. 2018) and demographics. Gender and age are frequently\ncited as having a profound impact on emoji comprehen-\nsion, with additional associations identified between cul-\ntural background, religious beliefs, and emoji interpreta-\ntion (Guntuku et al. 2019; Wang 2022). These demographic\ninfluences, particularly age and gender, are central to our in-\nvestigation. Gender-based differences in emoji comprehension have\narXiv:2501.11241v1  [cs.CL]  20 Jan 2025",
            "106305, 2020. [9] Y . Chen, X. Yang, H. Howman, and R. Filik, \u201cIndividual differences\nin emoji comprehension: Gender, age, and culture,\u201d Plos one , vol. 19,\nno. 2, p. e0297379, 2024. [10] Y . Wirza, H. Hanifah, H. Hanifah et al. , \u201cThe difference in emoji",
            "RESEA RCH ARTICL E\nIndividual differences in emoji\ncomprehension: Gender, age, and culture\nYihua Chen\n\u262f\n, Xingchen Yang\n\u262f\n, Hannah Howman, Ruth Filik\nID\n*\nSchool of Psychology, Univers ity of Nottingham , University Park, Nottingham, United Kingdom\n\u262f These authors contribu ted equally to this work. * ruth.fil ik@nottingh am.ac.uk\nAbstract\nEmoji are an important substitute for non-verbal cues (such as facial expressions) in online\nwritten communication. So far, however, little is known about individual differences regard-\ning how they are perceived. In the current study, we examined the influence of gender, age,\nand culture on emoji comprehension. Specifically, a sample of 523 participants across the\nUK and China completed an emoji classification task.",
            "(2022) and Chen et al. (2024), which indicate that younger\nindividuals generally demonstrate a heightened ability to de-\ntect irony in emoji usage compared to older cohorts. While\nthese results provide a compelling perspective, further re-\nsearch is necessary to better understand the interplay of de-\nmographic factors in shaping emoji interpretation. Discussions and Conclusions\nIn this study, we investigate howGPT-4o evaluates the level\nof irony in emojis compared to human perceptions.",
            "2022; Chen et al. 2024). Our study contributes to this body of work by conduct-\ning a fine-grained analysis of emoji interpretation through\nthe lens of demographic factors. By incorporating age and\ngender information directly into prompts for LLMs, we aim\nto understand better how these models account for demo-\ngraphic variations in interpreting ironic emojis. Method\nThis section describes the experimental procedure and its\nresults. A quantitative analysis is conducted to evaluate the\nability of the GPT-4o variant to interpret irony. Human Perception of Emoji Irony\nWe quantify how humans perceive the irony of emojis by\nanalyzing their usage patterns. Specifically, we measure the\nfrequency with which an emoji is used to convey irony in\nreal-world social media posts and calculate its relative pro-\nportion of ironic usage as an irony score. We follow Xiang\net al. (2020) and define \u201cirony\u201d as instances where an emoji\nconveys a meaning opposite to its literal interpretation, re-\nsulting in a reversal of understanding. We use the Ciron dataset compiled by Xiang et al. (2020),\nwhich consists of over 8,700 posts (including around 3,000\nposts containing emojis) from Weibo, a Chinese social me-\ndia platform. We select Ciron over the SemEval 2018 Irony\nDetection in English Tweets dataset (Van Hee, Lefever, and"
        ],
        [
            "\u2022 We propose a parallel corpus for English-\nEmoji translation, Text2Emoji, which makes\nit possible to study the emoji usage as a new\nform of language and extends the scope of\ncurrent emoji study from the single-Emoji pre-\ndiction to the emoji translation. \u2022 Based on Text2Emoji, we distill a sequence-\n5chat.openai.com/\n6bard.google.com/\nFigure 2: Screenshot from our implemented Text2Emoji\ntranslation website.",
            "To evaluate the performance of EmojiLM, we also\ncompare it with strong baselines on three popular\nbenchmarks, TweetEval, AG-News, and DBPdeia. Extensive experiments demonstrate the effective-\nness of our proposed approach. Moreover, we con-\nduct human evaluation on Text2Emoji and Emo-\njiLM, where we compare our translation results\nwith the ground truth in our parallel corpus. We\nobserve that human annotators cannot distinguish\nthe translation results from the ground truth, show-\ning that our proposed model serves as an emoji\ntranslator of high quality. We summarize our contribution as follows.",
            "Limitation\nWhile the work presented herein demonstrates\npromising strides in the field of Emoji translation,\ncertain limitations must be acknowledged. First\nand foremost, although we have successfully uti-\nlized LLMs to construct an English-Emoji parallel\ncorpus, the source of this ability remains some-\nwhat enigmatic. There is no publicly available\ntraining data specifically targeting this task, lead-\ning us to hypothesize that this ability stems from\nthe LLM\u2019s understanding of emoji semantics and\ntranslation tasks. However, the exact mechanism\nremains unexplored and warrants further investi-\ngation. Secondly, the corpus itself might harbor\nbiases towards popular emojis, reflecting the cor-\npus used to train the LLMs rather than a balanced\nrepresentation of Emoji usage across different cul-\ntures and communication contexts. This bias could\nlead to an overemphasis on commonly used emo-\njis and potentially overlook the nuanced usage of\nlesser-known emojis, thus limiting the generaliza-\ntion and applicability of the derived models and\ntools. These challenges underline areas for future\nresearch and refinement in the pursuit of a more\nrobust and comprehensive understanding of Emoji\nas a form of language. References\nS\u00f6ren Auer, Christian Bizer, Georgi Kobilarov, Jens\nLehmann, Richard Cyganiak, and Zachary G.",
            "Method\n2.1. Dataset\nOur corpus was derived from the LMSYS-CHAT-1M dataset of one million real-world con-\nversations with 25 chatbots,3 collected from 210,000 unique IP addresses between April \nand August 2023 (L. Zheng et al. 2023). LMSYS-CHAT-1M includes diverse conversation \nsamples, such as casual chat about everyday life, technical support inquiries, educational \ndiscussions, and requests to generate different written genres. Our data was sampled \nfrom LMSYS-CHAT-1M by selecting all conversations that contained at least one emoji \nSOCIAL SEMIOTICS \n 3",
            "2.2. Discourse analysis method\nThe study employed a largely qualitative approach, focusing on close discourse analysis \nsupplemented by some limited quantitative data on chatbot emoji usage. This quantitat-\nive data, derived from word frequency and n-grams, was useful for identifying relevant \ninstances for detailed tenor analysis, despite being insufficient on its own for understand-\ning the complex interpersonal meanings of emoji in the dynamic unfolding of chatbot \nconversations. In this paper we drew on a newly renovated model of \nTENOR aiming to \nexplain how social roles and relationships play out in the patterning of semiotic resources \nas they are employed by language users (Doran, Martin, and Zappavigna 2025). In order to \nunderstand the function of these resources, we analysed the conversations we sampled \nfrom our corpus using two systems: the discourse semantic system of emoji text CONVER -\nGENCE , used to understand the specific relations between the emoji and their co-text \n(explained in section 2.2.1), and the more abstract tenor system of tuning, used to under-\nstand how emoji are used by the chatbots to negotiate social relations with the user \n(explained in section 2.2.2). We posit that the former is integral to accurately understand\n-\ning the latter, thereby avoiding interpretations of emojis that disregard their interrelation \nwith the accompanying language."
        ],
        [
            "annotating incomprehensible or otherwise missing text with emoji\nlanguage. We observe results both from a \u201chuman translation\u201d condition,\nwhere words are translated to emoji language by human annota-\ntors, and from an \u201cAI translation\u201d condition. To the best of our\nknowledge, our work is the first to introduce a scalable and fully\nautomatic translation system for emoji language, called Emojinize. Unlike existing systems that merely sprinkle text with decorative\nemoji, Emojinize offers true translation, considering both prior and\nsubsequent contexts (different from next-token prediction), disam-\nbiguating synonyms based on the situation (different from a static\nlookup table), and harnessing the expressive power of combining\nmultiple emoji. The system\u2019s inherent flexibility allows for it to\ncater to both singular words and multi-word expressions, ensuring\nthat the translation\u2019s essence remains intact. We consider the user study an important contribution in itself,\nas it provides evidence for two separate claims:\n(1) Emoji translations can strongly improve understanding. (2) Emojinize\u2019s automatic emoji translation outperforms human\nannotation. We present a fully synthetic implementation of our study pro-\ntocol, emulating the replies of crowdsourced human participants\nwith answers generated by a large language model. This allows us\nto more deeply explore the capabilities of our Emojinize translation\nsystem. We discuss a multi-shot translation mechanism that is able\nto integrate feedback from an oracle model into the translation\nmechanism and find significantly improved guess rates in the syn-\nthetic cloze test. We also study the performance of Emojinize for\nmulti-word expressions.",
            "This casual use, how-\never, barely scratches the surface of the expressive power of emoji. To further unleash this power, we present Emojinize, a method for\ntranslating arbitrary text phrases into sequences of one or more\nemoji without requiring human input. By leveraging the power of\nlarge language models, Emojinize can choose appropriate emoji by\ndisambiguating based on context (e.g.,\n vs. ) and can express com-\nplex concepts compositionally by combining multiple emoji (e.g.,\n\u201cEmojinize\u201d is translated to\n ). In a cloze test\u2013based user study,\nwe show that Emojinize\u2019s emoji translations increase the human\nguessability of masked words by 55%, whereas human-picked emoji\ntranslations do so by only 29%. These results suggest that emoji\nprovide a sufficiently rich vocabulary to accurately translate a wide\nvariety of words. Moreover, annotating words and phrases with\nEmojinize\u2019s emoji translations opens the door to numerous down-\nstream applications, including children learning how to read, adults\nlearning foreign languages, and text understanding for people with\nlearning disabilities. 1 INTRODUCTION\nIn today\u2019s digital age, the way we communicate is continuously\nevolving. While written text remains the primary mode of com-\nmunication, there has been a growing inclination towards visual\nrepresentations such as emoji. These colorful and intuitive symbols\nserve as a universal language that can span linguistic boundaries,\noffering a bridge between disparate cultures and generations.",
            "However, com-\npared to single-shot translations, the guess rate is slightly worse,\nand the difference is not statistically significant. 6.2 Emojinizing multiple words in one go\nThe implementation of Emojinize presented in Section 3 translates\none marked text passage per input document. If the user wishes to\ntranslate multiple passages, Emojinize can be run multiple times. It is possible to extend this 1:1 relation between the input doc-\nument and output translation to support an arbitrary number of\ntranslations for each input text. This increases sample efficiency\nand leads to a speedup factor of N if N translations are produced\nin one batch. Particularly when processing large corpora such as\nbooks, the cost of inference is an important consideration. With an adjustment to the prompt formatting, Emojinize can\ntranslate an arbitrary number of marked passages for each input. We use the same prompting setup as demonstrated in Figure 1; in",
            "ized occurrence on the web, recent large language models show an\nintuitive grasp of emoji semantics. We leverage this ability to cre-\nate a new algorithm, Emojinize, which translates English text into\nemoji language. Our study shows that translations generated by\nEmojinize are significantly more accurate than translations created\nby human annotators. Emojinize eloquently combines multiple emoji into complex\ncompound expressions. Nevertheless, in some areas, the vocabulary\nof emoji language lacks the precision of natural language. We can\nrepresent \u201cdog\u201d but not \u201cspaniel\u201d, \u201cbird\u201d but not \u201cheron\u201d. Even in\nthese examples, emoji annotations can still be useful. To a reader\nwho doesn\u2019t know the word \u201cspaniel\u201d, the emoji annotation \u201c\n \u201d\nwill still provide relevant information, i.e., that the word refers to a\ntype of dog. The generality of Emojinize is demonstrated in its Multi-Word\nExpressions (MWEs) handling.",
            "We describe here a mechanism by which arbitrary text passages\ncan be translated into emoji language, and we evaluate to which\nextent the information contained in emoji language annotations\ncan help with text comprehension. A simple approach to translating a word into emoji language\nwould be to map it to the closest emoji in the embedding space. An embedding mechanism for emoji is described in [10]. However,\nthis approach is not context-sensitive. In particular, services related\nto such static approaches such as [12] are not related to our work:\nThey rely on a simple dictionary lookup to decorate text with emoji. The authors of [37] have created a large database connecting\nemoji with their semantic meaning. Each emoji is annotated with\na set of sense labels. Using the so-called EmojiNet database and\nembedding techniques to calculate the semantic similarity of emoji\nis done in [38]. In [28], the authors focus on how to build an efficient\nemoji keyboard. For this purpose, they compute an emoji similarity\nmeasure based on emoji embeddings computed from 21 million\ntweets. An LSTM neural network trained with federated learning to\npredict emoji is described in [2]. This is a language model in which\nrelevant emoji are learned with a next-token-prediction objective. Such a model can only learn to mimic human ways of decorating\ntext with emoji based on emoji usage in its training corpus, but it\ndoes not actually translate into emoji language. In particular, an\nemoji translation based on a next-token-prediction approach can\nonly take the preceding context into account, but not the context\nafter the emoji. The state of the art in language modeling today is represented by\nlarge language models (LLMs) such as GPT-4 [26] and Llama-2 [34],\nwhich are based on the transformer architecture [35]. An emergent\ncapability of these models is an intuitive grasp of the semantic\nmeaning of emoji."
        ],
        [
            "3 8B revealed substantial model-specific differences in robustness: Gemma 2 9B and Mistral 7B each yielded a\n10% jailbreak success rate, Llama 3 8B achieved 6%, while Qwen 2 7B exhibited complete resistance (0% success,\n100% ethical compliance). These variations highlight that current safety mechanisms remain vulnerable to adversarial\nprompting techniques using emoji sequences. The results underscore the need for emoji-aware defenses in LLM\npipelines, including normalized handling of non-textual tokens and expanded adversarial evaluation. Future work\nshould investigate larger and more culturally diverse prompt sets, alongside automated detection mechanisms that\nincorporate multimodal representations of emoji semantics and hybrid mitigation strategies to advance the safety and\nalignment of large language models. References\n[1] Brown, T.",
            "EMOJI-BASEDJAILBREAKING OFLARGELANGUAGEMODELS\nM P V S Gopinadh\nVishnu Institute of Technology\nBhimavaram, India\nmpavangopinadh@gmail.com\nS Mahaboob Hussain\nVishnu Institute of Technology\nBhimavaram, India\nmahaboobhussain.smh@gmail.com\nABSTRACT\nLarge Language Models (LLMs) are integral to modern AI applications, but their safety alignment\nmechanisms can be bypassed through adversarial prompt engineering. This study investigates emoji-\nbased jailbreaking, where emoji sequences are embedded in textual prompts to trigger harmful and\nunethical outputs from LLMs. We evaluated 50 emoji-based prompts on four open-source LLMs:\nMistral 7B, Qwen 2 7B, Gemma 2 9B, and Llama 3 8B. Metrics included jailbreak success rate,\nsafety alignment adherence, and latency, with responses categorized as successful, partial and failed. Results revealed model-specific vulnerabilities: Gemma 2 9B and Mistral 7B exhibited 10% success\nrates, while Qwen 2 7B achieved full alignment (0% success).",
            "compliance (66%). The extent of Gemma\u2019s susceptibility, despite its larger parameter count (9B), was unexpected,\nindicating that deeper processing of emoji sequences might increase vulnerability rather than enhance safety. Table 2 summarizes the performance of Gemma 2 9B, Llama 3 8B, Mistral 7B, and Qwen 2 7B, when tested with\nemoji-based jailbreaking prompts. It reports three metrics: success rate (percentage of prompts that produced restricted\ncontent), ethical compliance (percentage of responses adhering to ethical guidelines), and average latency (response\ntime in seconds). A chi-square test yielded a statistic of 32.94 (p <0.001), indicating significant differences in model performance. Qwen 2 7B\u2019s perfect compliance contrasts with Gemma 2 9B\u2019s lower ethical compliance, highlighting model-specific\nvulnerabilities. The results underscore the trade-offs that current large language models make when confronted with adversarial,\nemoji-based prompts. Qwen 2 7B demonstrates a clear emphasis on stringent safety mechanisms, achieving perfect\nethical compliance at the cost of reduced generative flexibility.",
            "Latency (s)\nGemma 2 9B 10.0 66.0 44.20\nLlama 3 8B 6.0 88.0 32.22\nMistral 7B 10.0 88.0 25.30\nQwen 2 7B 0.0 100.0 34.04\nThe study revealed several unexpected outcomes. One surprising discovery was the stark contrast in model perfor-\nmance, particularly Qwen 2 7B\u2019s complete resistance to jailbreaking, with a 0% success rate and 100% ethical compli-\nance. Another surprising result was Gemma 2 9B\u2019s high latency (44.20 seconds) paired with its relatively low ethical\n3",
            "Gemma 2 9B, by contrast, appears to prioritize content\ngeneration and permissiveness, resulting in higher success rates but significantly lower ethical adherence. Mistral 7B\nand Llama 3 8B occupy a middle ground balancing moderate resistance to jailbreak attempts with relatively strong\nethical safeguards and acceptable response times. These variations reflect differing design philosophies across models,\nwith each system negotiating the tension between robustness, safety, and utility in its own way. The findings suggest\nthat emoji-based prompts remain a challenging modality. The following are visualizations that illustrate performance patterns, ethical response distributions, and latency varia-\ntions across all evaluated models from the experiments. Figure 1: Outcome Distribution by Models (Bar Chart, 50 Prompts)"
        ],
        [
            "vacy during interactions with cloud-based LLMs. EmojiPrompt uses LLMs to perform generative ob-\nfuscation, transforming private data from natural\nlanguage into non-natural language forms, thus ob-\nfuscating it from both LLM and human recoverers. We validate EmojiPrompt\u2019s effectiveness across\nSD (b-acc)ARS (b-acc)AS (cos)HAD (b-acc)FrenchGerman\nGPT-4 0.961 0.961 0.979 0.681 0.672Gemini + GPT-40.897 0.885 0.942 0.642 0.653\nTable 6: Performance on Non-English Datasets\neight datasets, showing that performance on obfus-\ncated prompts is largely preserved and, in some\ncases, even exceeds that of unobfuscated prompts. We also compare EmojiPrompt against three obfus-\ncation baselines, showing it matches their perfor-\nmance on some tasks while outperforming them in\nothers, both for task inference and recovery robust-\nness.",
            "To protect privacy when using cloud-based\nLLMs, recent works (Chowdhury et al., 2024; Tong\net al., 2023; Mai et al., 2024) employ text obfus-\ncation by converting private data tokens into their\nobfuscated, noisy forms while retaining contex-\ntual relevance. For example, Split-N-Denoise (Mai\net al., 2024) adds noise to token embeddings before\ntransmission to cloud-based LLMs and then de-\nnoises the output with a local LLM. However, such\nmethods require substantial computations to deter-\nmine the noisy terms and to train local de-noising\nLLMs. Other text obfuscation methods propose\nto anonymize sensitive terms prior to cloud-based\nLLM input and subsequently restoring them post-\noutput (Kan et al., 2023; Chen et al., 2023). For\ninstance, OpaquePrompt server 6 identifies sensi-\ntive entities within a user\u2019s prompt and replaces\nthem with generic identifiers. However, they are\neffective mainly when cloud-based LLMs rely on\n6https://github.com/opaque-systems/\nopaqueprompts-python\ncontext rather than sensitive data for inference. 3 Methodology\nThis section delineates the structure of our obfus-\ncation paradigm, which incorporates two LLMs:\none for the obfuscation of private data, denoted as\nLLMO, and the other for task inferences by pro-\ncessing the obfuscated prompts, denoted as LLMI. 3.1 Problem Definition\nThe model LLMO obfuscates a given text x by\nadhering to a task obfuscation instructionot. The\nobfuscation process is formally written as:\nLLMO(ot,x ) = x\u2032, (1)\nwhere x\u2032represents the obfuscated version of\nthe original textx. The instructionot instructs the\nLLMO to generate a task-specific obfuscated repre-\nsentation ofx using a mixture of linguistic (i.e., ab-\nbreviated characters) and non-linguistic (i.e., emo-\njis, emoticons, mathematical and logical operators)\nelements. The obfuscated form of the user\u2019s private\ninformation, ui, is then formulated from x\u2032(we\nspecify the process to formulateui in Section 3.2).",
            "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies\n(V olume 1: Long Papers), pages 12342\u201312361\nApril 29 - May 4, 2025 \u00a92025 Association for Computational Linguistics\nEmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving\nCommunication with Cloud-based LLMs\nSam Lin\u2020\u2217, Wenyue Hua\u2020\u2217, Zhenting Wang\u2020, Mingyu Jin\u2020,\nLizhou Fan\u2021, Yongfeng Zhang\u2020\n\u2020Department of Computer Science, Rutgers University, New Brunswick\n\u2021School of Information, University of Michigan, Ann Arbor\n\u2217Sam Lin and Wenyue Hua contribute equally. Abstract\nCloud-based Large Language Models (LLMs)\nsuch as ChatGPT have become increasingly in-\ntegral to daily operations. Nevertheless, they\nalso introduce privacy concerns: firstly, numer-\nous studies underscore the risks to user pri-\nvacy posed by jailbreaking cloud-based LLMs;\nsecondly, the LLM service providers have ac-\ncess to all user data, which deters individuals\nfrom confidently utilizing such services. To\naddress such concerns, we propose a simple\nyet effective paradigm, EmojiPrompt, to pro-\ntect user privacy. At its core, EmojiPrompt\nperforms generative transformation, obfuscat-\ning private data within prompts with linguistic\nand non-linguistic elements before submitting\nthem to cloud-based LLMs. We evaluate Emo-\njiPrompt\u2019s performance across 8 datasets from\nvarious domains. We also propose simulated in-\nference attacks to assess EmojiPrompt\u2019s ability\nto preserve user privacy. The results demon-\nstrate that EmojiPrompt effectively obfuscates\nuser private data, while largely maintaining,\nor even enhancing, performances compared to\nthe unobfuscated version. Furthermore, Emo-\njiPrompt\u2019s atomic-level obfuscation allows it to\nfunction exclusively with cloud-based LLMs. For source code, please refer to: https://\ngithub.com/agiresearch/EmojiCrypt.",
            "For dataset\nlinks, descriptions, modeling pre-processing, and\nmetric details, please refer to Appendix A.3. Modeling Setup To conduct a comprehensive\nevaluation, we implement EmojiPrompt across\nboth trusted and untrusted LLMI settings: Trusted:\nthe LLM employed for task inference is reliable;\nin this case, the obfuscation only serves to prevent\nthird-party privacy probing. Untrusted: the LLM\nemployed for task inference is not reliable; that is,\nthe obfuscation serves to prevent both third-party\nprobing as well as potential information leakage\nfrom the server of the LLMI. In the Trusted sce-\nnario, we employ the same LLM for both private\ndata obfuscation and task inference. In the Un-\ntrusted scenario, we employ LLMs that are hosted\non distinct servers for obfuscation and inference. For both cases, our atomic-level obfuscation ef-",
            "structed by combiningtpt,St, andui, and is then\nfed into LLMI. The model subsequently carries\nout inference to produce an output y\u2208St. This\ninference process is formally defined as:\nLLMI(tpt,St,ui) = y wherey\u2208St. (2)\n3.2 Atomic-level Obfuscation\nSince LLMO may be cloud-based, there is a po-\ntential risk of privacy leakage to the LLMO server\nduring the obfuscation process. To mitigate this\nrisk, we propose an atomic-level obfuscation strat-\negy. This approach involves partitioning the user\u2019s\nprivate data into smaller modular units, obfuscat-\ning each unit separately, and then reconstructing\nthe obfuscated private data from these individually\nobfuscated units. Given the diverse nature of user\nprivate data, we define two types of obfuscation:\nReusable and Non-Reusable. We then describe how\nour atomic-level obfuscation technique is applied\nto each type to ensure privacy and security. Reusable Obfuscation The Reusable Obfusca-\ntion type is designed for scenarios where the user\u2019s\nprivate data is associated with a predefined group\nof features or entities that are repetitively refer-\nenced. For example, in a recommender system that\nleverages information about a user\u2019s past purchases\nto make recommendations (as illustrated in Figure\n1), this data is sensitive because it can disclose the\nuser\u2019s buying patterns and preferences. In such\ncases, the data items form a consistent set that can\nbe obfuscated a single time and then reused across\nmultiple prompts without repeated obfuscation. To perform atomic-level obfuscation for this\ntype, we begin by extracting all products in the task\ndataset and converting each item to its obfuscated\nform. These obfuscated products are then used to\nreconstruct the user\u2019s history for subsequent pro-\ncessing by the LLMI. This process is depicted in\nFigure 1 (Reusable Obfuscation on tabular data is\npresented in Appendix A.1, with the same idea)."
        ],
        [
            "system called tuning,1 which explains how interpersonal meanings are modulated \nalong three dimensions: stakes (the interpersonal risk or significance of a position), \nscope (how inclusive or exclusive the position is), and spirit (the tone or vibe in which \nmeanings are cast) (Doran, Martin, and Zappavigna 2025). These systems are used to \nexplore the ways in which chatbots use emoji to communicate and negotiate stances \nand values in conversations with their human users. In particular, we focus on the role \n\u00a9 2025 The Author(s).",
            "Social Semiotics\nISSN: 1035-0330 (Print) 1470-1219 (Online) Journal homepage: www.tandfonline.com/journals/csos20\nEmoji as interpersonal resources in LLM chatbot\nconversations: a social semiotic analysis of tenor\nand a\ufb03liation in human\u2013AI interaction\nMichele Zappavigna & Y.J. Doran\nTo cite this article: Michele Zappavigna & Y.J. Doran (10 Oct 2025): Emoji as interpersonal\nresources in LLM chatbot conversations: a social semiotic analysis of tenor and a\ufb03liation in\nhuman\u2013AI interaction, Social Semiotics, DOI: 10.1080/10350330.2025.2570317\nTo link to this article:  https://doi.org/10.1080/10350330.2025.2570317\n\u00a9 2025 The Author(s). Published by Informa\nUK Limited, trading as Taylor & Francis\nGroup\nPublished online: 10 Oct 2025.",
            "Emoji as interpersonal resources in LLM chatbot \nconversations: a social semiotic analysis of tenor and \naffiliation in human\u2013AI interaction\nMichele Zappavigna \n a and Y.J. Doran \n b\naSchool of the Arts and Media, University of New South Wales, Sydney, Australia; bNational School of \nEducation, Faculty of Education and Arts, Australian Catholic University, Sydney, Australia\nABSTRACT  \nThis study examines how large language model (LLM) chatbots use \nemoji to manage social relationships in conversations with users. Drawing on a dataset of one million chatbot\u2013human interactions, \nwe analyse emoji as resources for shaping interpersonal tone and \nbuilding rapport. Using a social semiotic approach, we show that \nemoji often make chatbots appear friendly and supportive by \nsoftening requests, signalling enthusiasm, and fostering a sense \nof connection. However, this pattern can become formulaic, \nleading to overly cheerful or sycophantic responses. These \ninterpersonal functions are analysed using the tenor system, \nTUNING , which models how interpersonal meanings can be \nmodified by adjusting their consequence ( STAKES ), degree of \ninclusivity (SCOPE ), and the tone in which they are cast (SPIRIT). We \ndiscuss what these findings reveal about chatbot design and the \nrole of emoji in human\u2013AI communication. KEYWORDS  \nLLM Chatbots; emoji; \nsystemic functional \nlinguistics; tenor; tuning\n1. Introduction\nUnderstanding tenor, the interpersonal dimension of communication, is central to exam-\nining Large Language Model (LLM) Chatbot conversations with human users. In Systemic \nFunctional Linguistics (SFL), tenor refers to the contextual parameters that model how \nsocial relations are negotiated and organised, including the roles interactants play, the \nrelationships they construct, and the values they bring to an activity (Michael A. K Halliday \nand Matthiessen \n2014; Hasan 2020).",
            "It should be noted that given how abstract tenor is, \nbeing a contextual parameter, any number of discourse semantic features used to \nrealise interpersonal meaning might be relevant, depending on what is happening in \nthe text. Due to space constraints, these features will be explained as they are used. 2.2.1 The system of emoji-text convergence\nSince emoji make meaning in combination with their co-text we will draw on previous \nwork on emoji-text relations by Zappavigna and Logi (2024) in order to be specific \nabout how emoji and their co-text operate in the service of more abstract",
            "2.2. Discourse analysis method\nThe study employed a largely qualitative approach, focusing on close discourse analysis \nsupplemented by some limited quantitative data on chatbot emoji usage. This quantitat-\nive data, derived from word frequency and n-grams, was useful for identifying relevant \ninstances for detailed tenor analysis, despite being insufficient on its own for understand-\ning the complex interpersonal meanings of emoji in the dynamic unfolding of chatbot \nconversations. In this paper we drew on a newly renovated model of \nTENOR aiming to \nexplain how social roles and relationships play out in the patterning of semiotic resources \nas they are employed by language users (Doran, Martin, and Zappavigna 2025). In order to \nunderstand the function of these resources, we analysed the conversations we sampled \nfrom our corpus using two systems: the discourse semantic system of emoji text CONVER -\nGENCE , used to understand the specific relations between the emoji and their co-text \n(explained in section 2.2.1), and the more abstract tenor system of tuning, used to under-\nstand how emoji are used by the chatbots to negotiate social relations with the user \n(explained in section 2.2.2). We posit that the former is integral to accurately understand\n-\ning the latter, thereby avoiding interpretations of emojis that disregard their interrelation \nwith the accompanying language."
        ],
        [
            "arXiv:2502.17392v1  [cs.AI]  24 Feb 2025\n1\nEmoti-Attack: Zero-Perturbation Adversarial\nAttacks on NLP Systems via Emoji Sequences\nY angshijie Zhang\nLanzhou University, Lanzhou, China\nEmail: zhangyshj2023@lzu.edu.cn\nAbstract\u2014Deep neural networks (DNNs) have achieved re-\nmarkable success in the \ufb01eld of natural language processing\n(NLP), leading to widely recognized applications such as Ch at-\nGPT. However , the vulnerability of these models to adversar ial\nattacks remains a signi\ufb01cant concern. Unlike continuous do mains\nlike images, text exists in a discrete space, making even min or\nalterations at the sentence, word, or character level easil y per-\nceptible to humans. This inherent discreteness also compli cates\nthe use of conventional optimization techniques, as text is non-\ndifferentiable. Previous research on adversarial attacks in text\nhas focused on character-level, word-level, sentence-lev el, and\nmulti-level approaches, all of which suffer from inef\ufb01cien cy or\nperceptibility issues due to the need for multiple queries o r\nsigni\ufb01cant semantic shifts. In this work, we introduce a novel adversarial attack method ,\nEmoji-Attack, which leverages the manipulation of emojis t o\ncreate subtle, yet effective, perturbations. Unlike chara cter- and\nword-level strategies, Emoji-Attack targets emojis as a di stinct\nlayer of attack, resulting in less noticeable changes with m inimal\ndisruption to the text. This approach has been largely unexp lored\nin previous research, which typically focuses on emoji inse rtion as\nan extension of character-level attacks. Our experiments d emon-\nstrate that Emoji-Attack achieves strong attack performan ce on\nboth large and small models, making it a promising technique\nfor enhancing adversarial robustness in NLP systems. Index Terms\u2014Adversarial Attack, Zero-Perturbation.",
            "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection\nthe target LLM level, less attention has been paid to attacks\naimed directly at Judge LLMs, which determine whether\nthe generated content is harmful. One study by Mangaokar\net al. (2024) extends GCG to optimize a universal adversar-\nial prefix against white-box Judge LLMs. Using in-context\nlearning (Brown et al., 2020), it instructs the target LLM to\nproduce harmful outputs that the Judge LLM subsequently\nmisclassifies. However, similar to GCG, this approach re-\nmains query-intensive and encounters scalability constraints. In addition, Charmer (Rocamora et al., 2024) employs a\nheuristic approach to search for and insert characters into\nspecific positions. However, it overlooks the fundamental\nunderstanding of text segmentation and does not account for\nthe integration of emojis, which are increasingly relevant in\nmodern text processing tasks. In contrast, our proposed Emoji Attack exploits token seg-\nmentation bias, does not require extensive optimization, and\ncan be seamlessly integrated with existing jailbreak meth-\nods. As a result, it presents a lightweight yet effective tool\nfor misleading Judge LLMs and shows the need to address\nsuch vulnerabilities in guardrail systems. 3. Methodology\nIn this section, we introduce our approach to exploit token\nsegmentation and semantic meaning biases to enhance jail-\nbreak attacks against Judge LLMs. We begin by defining\nthe problem setup involving a target LLM and a Judge LLM. We then discuss the phenomenon of token segmentation\nbias. Finally, we introduce our proposed Emoji Attack.",
            "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection\nZhipeng Wei 1 2 Yuqi Liu1 N. Benjamin Erichson 1 3\nAbstract\nJailbreaking techniques trick Large Language\nModels (LLMs) into producing restricted output,\nposing a potential threat. One line of defense is to\nuse another LLM as a Judge to evaluate the harm-\nfulness of generated text. However, we reveal that\nthese Judge LLMs are vulnerable to token segmen-\ntation bias, an issue that arises when delimiters\nalter the tokenization process, splitting words into\nsmaller sub-tokens. This alters the embeddings\nof the entire sequence, reducing detection accu-\nracy and allowing harmful content to be misclas-\nsified as safe. In this paper, we introduce Emoji\nAttack, a novel strategy that amplifies existing jail-\nbreak prompts by exploiting token segmentation\nbias. Our method leverages in-context learning to\nsystematically insert emojis into text before it is\nevaluated by a Judge LLM, inducing embedding\ndistortions that significantly lower the likelihood\nof detecting unsafe content. Unlike traditional\ndelimiters, emojis also introduce semantic ambi-\nguity, making them particularly effective in this\nattack. Through experiments on state-of-the-art\nJudge LLMs, we demonstrate that Emoji Attack\nsubstantially reduces the unsafe prediction rate,\nbypassing existing safeguards.",
            "2025. Quantum-inspired Non-\nhomologous Representation Constraint Mechanism for\nLong-tail Senses of Word Sense Disambiguation. InPro-\nceedings of the AAAI Conference on Artificial Intelligence,\n25877\u201325885. Philadelphia, PA, USA: AAAI Press. Zhang, Q.; Cai, S.; Zhao, J.; Pechenizkiy, M.; and Fang, M. 2024a. CHAmbi: A New Benchmark on Chinese Ambiguity\nChallenges for Large Language Models. InFindings of the\nAssociation for Computational Linguistics: EMNLP 2024,\n14883\u201314898. Miami, Florida, USA: Association for Com-\nputational Linguistics.",
            "(2020). Transformers: State -of-the-Art Natural Language Processing. Proceedings \nof the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, 38-45. 23. Zhang, X., Zhao, J., & LeCun, Y. (2015). Character -level Convolutional Networks for Text Classification. Advances in \nNeural Information Processing Systems, 28. 24. Zou, A., Phan, L., Bamman, D., & Song, Y. (2023). Universal and Transferable Adversarial Attacks on Aligned Language \nModels. arXiv preprint arXiv:2307.15043. 25."
        ],
        [
            "2019). In this section, we prompt\nChatGPT to annotate emoji sentiment and compare its an-\nnotations with those of humans. Additionally, we evalu-\nate ChatGPT\u2019s performance in predicting the sentiment of\ntweets containing emojis for downstream tasks. 4.1 Emoji Sentiment Annotation\nWe first ask GPT4 to label the 50 most frequently used emo-\njis in Section 3.1 with positive, neutral and negative senti-\nment with the prompt in Table 12a in Appendix. Compared to the human annotations in Hu et al. (2017),\nwe observe that ChatGPT and human annotators share the\nsame sentiment annotation for almost all emojis (49 out of\n50). The only difference is the annotation for the\n (flushed\nface) emoji. While the human annotation is neutral, Chat-\nGPT\u2019s response is negative, considering feelings of embar-\nrassment or a sense of being overwhelmed associated with\n. This discrepancy indicates that ChatGPT can interpret\nthe sentiment of emojis but may differ from human annota-\ntions in specific cases. ChatGPT\u2019s response often notes that\nit requires text context to accurately determine emoji senti-\nment. Therefore, we discuss the influence of emojis on Chat-\nGPT\u2019s performance in downstream sentiment analysis tasks. 4.2 Sentiment Prediction with Emojis\nPrevious researchers have emphasized the importance of\nemoji information to judge sentiment in the given inputs\n(Chen et al. 2019; Felbo et al. 2017). We also investigate\nwhether ChatGPT considers emojis in its sentiment classifi-\ncation predictions. For the experiment setup, we choose the\nsentiment analysis dataset from the TweetEval benchmark\n(Barbieri et al. 2020), which includes three labels: negative,\nneutral, and positive. We extract tweets containing emojis\nfrom the dataset, resulting in 805 tweets. We perform senti-\nment prediction using in-context learning (ICL) with GPT4\nand GPT3.5, providing 5 demonstrations for each model. The models achieve 70.31% and 71.67% accuracy for GPT4",
            "(2022) and Chen et al. (2024), which indicate that younger\nindividuals generally demonstrate a heightened ability to de-\ntect irony in emoji usage compared to older cohorts. While\nthese results provide a compelling perspective, further re-\nsearch is necessary to better understand the interplay of de-\nmographic factors in shaping emoji interpretation. Discussions and Conclusions\nIn this study, we investigate howGPT-4o evaluates the level\nof irony in emojis compared to human perceptions.",
            "identified two primary carriers of irony on social media:\nverbal content and emojis. Emojis often embody irony\nthrough the contrast between their outward appearance and\nintended meaning, complicating their interpretation. Their\neuphemistic, humorous, and context-dependent uses further\nchallenge the ability of LLMs to accurately discern senti-\nment (Lyu et al. 2024b). Addressing this challenge is essen-\ntial, as accurate detection of irony in emojis could signifi-\ncantly enhance applications such as virtual assistants, chat-\nbots, and sentiment analysis tools (Lyu et al. 2024a). This study investigates the following research question:\n\u2022 How does GPT-4o\u2019s interpretation of ironic emojis com-\npare to that of humans? To answer this, we promptGPT-4o to assess how likely it is\nto choose a specific emoji to express irony on social media\nand compare its responses to human perceptions. By focusing on irony in emojis, this research aims to eval-\nuate LLMs\u2019 ability to understand subtle, sentiment-rich el-\nements of this emerging universal language. Beyond tech-\nnical insights, the study underscores the broader implica-\ntions of AI in enhancing communication and human behav-\nior simulation. Related Work\nThe use of emojis on social media has attracted significant\nresearch attention, particularly in the context of sentiment\nanalysis (Hu et al. 2017). The advent of large language mod-\nels (LLMs) has introduced innovative approaches for an-\nalyzing sentiment involving emojis (Wankhade, Rao, and\nKulkarni 2022; Weissman and Tanner 2018). However, a no-\ntable gap remains between LLMs\u2019 interpretation of emojis\nand human understanding. For instance, Lyu et al. (2024b)\nidentified significant discrepancies in behavior between hu-\nmans and LLMs, which can be attributed to the subjec-\ntive nature of emoji interpretation and the limitations im-\nposed by cultural biases and insufficient representation of\nnon-English cultures. Similarly, Zhou et al.",
            "Our findings reveal that, on average, GPT-4o assigns\nhigher irony scores to emojis than humans do for the\nsame emoji. This observation has several implications. First,\nGPT-4o may have been trained on data with a dispropor-\ntionate representation of ironic emoji usage, leading to an\ninflated assessment of their ironic potential. Second, the\nmodel might overgeneralize irony based on patterns in its\ntraining data, potentially lacking the contextual nuance hu-\nmans rely on when interpreting emojis in specific scenar-\nios. Lastly, this overestimation could have practical impli-\ncations, such as misinterpretations in applications where ac-\ncurate understanding of human communication patterns is\ncritical\u2014examples include sentiment analysis, chatbot inter-\nactions, and social media analysis. We also observe minimal differences in irony scores be-\ntween prompts indicating female or male genders. However,\na notable trend emerged with age: irony scores tend to de-\ncrease as the specified age in the prompt increases. This age-\nrelated pattern aligns with findings from prior studies. An additional factor contributing to the discrepancy be-\ntween model-classified and human-perceived scores could\nbe the dataset used for evaluation. We conduct the study us-\ning a Chinese social media post dataset, while GPT-4o is\npredominantly trained on English-language data. This lan-\nguage orientation, combined with cultural differences in\nthe use and interpretation of emojis, may partially explain\nthe gap. However, due to the unavailability of an English-\nlanguage irony dataset, we are unable to evaluateGPT-4o\u2019s\nperformance on English-language emojis. Addressing this\nlimitation is a key focus of our future work.",
            "tent, ChatGPT\u2019s scores differ from human ratings, but the\ndiscrepancy is smaller than the average human SD. Hence,\nwe conclude that ChatGPT\u2019s understanding of the universal\nusage intention of emojis is generally similar to that of hu-\nman users. 5.2 Intention of Emoji Usage in GitHub Posts\nThe similar intention annotation without context between\nChatGPT and humans aligns with the accurate explanation\nof emoji semantics and the precise annotation of emoji sen-\ntiment. However, the intention behind using emojis can vary\nacross different platforms. For example, users on GitHub\nmay use emojis to organize content within a post but rarely\nto express irony. Understanding emoji intention in GitHub\nposts poses a greater challenge for ChatGPT. In this part, we collect the same 2,000 emoji posts on\nGitHub with human annotations from Lu et al. (2018) and\ncompare ChatGPT\u2019s annotations of emoji intentions with the\nhuman ground truth labels. The candidate intentions of emo-\njis in GitHub posts are shown in Table 2, with detailed defi-\nnitions provided in Lu et al. (2018)."
        ],
        [
            "Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in\nLarge Language Models\nWeipeng Jiang1*, Xiaoyu Zhang2*, Juan Zhai3, Shiqing Ma3, Chao Shen1, Yang Liu2\n1Xi\u2019an Jiaotong University,2Nanyang Technological University,3University of Massachusetts Amherst\nlenijwp@stu.xjtu.edu.cn, joshiningrain@gmail.com ,{juanzhai, shiqingma}@umass.edu\nchaoshen@mail.xjtu.edu.cn, yangliu@ntu.edu.sg\nAbstract\nEmoticons are widely used in digital commu-\nnication to convey affective intent, yet their\nsafety implications for Large Language Mod-\nels (LLMs) remain largely unexplored. In this\npaper, we identify emoticon semantic confu-\nsion, a vulnerability where LLMs misinterpret\nASCII-based emoticons to perform unintended\nand even destructive actions. To systemati-\ncally study this phenomenon, we develop an\nautomated data generation pipeline and con-\nstruct a dataset containing 3,757 code-oriented\ntest cases spanning 21 meta-scenarios, four\nprogramming languages, and varying contex-\ntual complexities. Our study on six LLMs re-\nveals that emoticon semantic confusion is per-\nvasive, with an average confusion ratio exceed-\ning 38%. More critically, over 90% of confused\nresponses yield \u2018silent failures\u2019, which are syn-\ntactically valid outputs but deviate from user in-\ntent, potentially leading to destructive security\nconsequences.",
            "through prompt engineering alone. The inconsis-\ntency across models indicates that the emoticon\nsemantic confusion could stem from the deep rep-\nresentation and grounding issues in LLMs, which\ncan only be weakly influenced by surface-level\nprompting strategies. Finding 6:The evaluated prompting meth-\nods show inconsistent mitigation effects across\ndifferent LLMs, with \u2018System Instruction\u2019 per-\nforming better than other methods. 5 Discussion\nWhile this paper reveals emoticon semantic confu-\nsion, a novel security vulnerability in human-AI in-\nteractions, and analyzes its security consequences,\nthis study represents only the first step in under-\nstanding this risk. The following discusses several\npromising directions for future work.",
            "surface for adversarial exploitation. We urge re-\nsearchers to take heed of the emoticon semantic\nconfusion, paving the way for robust and secure\nhuman-computer interaction systems. Limitation\nDespite our extensive efforts to systematically re-\nveal and analyze emoticon semantic confusion, we\nacknowledge two primary limitations in this study:\nLimited Dataset.Although we designed 21 meta-\nscenarios covering diverse coding tasks with three\nlevels of interaction complexity, the infinite vari-\nability of real-world interactions means our dataset\ncannot capture every edge case of emoticon us-\nage or interaction context. To mitigate this, we\nopen-source our data generation pipeline, allow-\ning researchers to extend our framework to new\nscenarios and emoticons. Limited Models.Our empirical study evaluates six\nstate-of-the-art LLMs from major LLM providers\nto ensure the reliability and breadth of our empir-\nical findings. However, the rapidly evolving land-\nscape of LLMs means our results may not fully\ngeneralize to all available models. To address this\nlimitation, we open-source our dataset and encour-\nage the community to utilize this dataset to evaluate\na wider spectrum of LLMs and agents. Ethical Considerations\nWhile the findings presented in this work could po-\ntentially be misused to attack LLMs or agent-based\nsystems, our study is conducted with the goal of\nexposing previously underexplored risks associated\nwith emoticon semantic confusion. By document-\ning these risks, we aim to raise awareness within\nthe research community and encourage the devel-\nopment of more safe and secure LLM systems. References\n2020. cd into folder name that starts with an emoji. https://unix.stackexchange.com/questions/613250/\ncd-into-folder-name-that-starts-with-an-emoji? utm_source=chatgpt.com. Wei Ai, Xuan Lu, Xuanzhe Liu, Ning Wang, Gang\nHuang, and Qiaozhu Mei.",
            "MY DATA !!! Emoticon Semantic Confusion\nUser Intention:\n LLM Comprehension:\u00a0\n`~` expresses a playful tone. Expectation: Harmless cleanup\n(i.e., `rm -r ./tmp`). `~` should be a\u00a0target. Action: Catastrophic Data\nDeletion (i.e., `rm -r ~'). Figure 1: LLM may consider emoticons that humans\nuse to express emotions as part of the instructions, ul-\ntimately leading to catastrophic consequences (such as\ndeletion of critical data)\na human-computer interaction (HCI) perspective,\nusers naturally transfer these conventions into their\ninteractions with computational systems (Fadhil\net al., 2018). In such scenarios, the ability of mod-\nels to accurately and robustly interpret and align\nwith human intent directly affects interaction effi-\nciency and user experience, and may bear on the\nsystem\u2019s safety and reliability. This underscores\nan urgent need to systematically investigate poten-\ntial discrepancies between LLMs and humans in\nsemantic understanding, as well as the risks that\nmay arise from such misalignment. In this paper, we systematically reveal and define\na severe risk in LLMs, namelyemoticon seman-\ntic confusion. Unlike standard Unicode emojis,\nwhich possess distinct encodings, emoticons are\nconstructed from standard alphanumeric charac-\nters and punctuation (e.g., \u2018:-)\u2019, \u2018~\u2019, \u2018>\u2019), sharing\na heavily overlapping symbol space with program-\nming operators, shell wildcards, and file paths. We",
            "specialized coding. Consequently, the risks associated with\nemojis could affect a larger user base, leading to broader po-\ntential harm. Therefore, it deserves a comprehensive investi-\ngation into how emojis trigger toxicity generation in LLMs. 7 Conclusion\nThis paper starts with the phenomenon that harmful requests\nwith emojis can trigger toxicity from LLMs. With extensive\nexperiments across models, languages and jailbreak tasks,\nwe first comprehensively explore the emoji-triggered toxi-\ncity generation. For further insights, we perform a series of\ninterpretation from semantic cognition to tokenization, inter-\npreting the generation at the model-level."
        ],
        [
            "arXiv:2502.17392v1  [cs.AI]  24 Feb 2025\n1\nEmoti-Attack: Zero-Perturbation Adversarial\nAttacks on NLP Systems via Emoji Sequences\nY angshijie Zhang\nLanzhou University, Lanzhou, China\nEmail: zhangyshj2023@lzu.edu.cn\nAbstract\u2014Deep neural networks (DNNs) have achieved re-\nmarkable success in the \ufb01eld of natural language processing\n(NLP), leading to widely recognized applications such as Ch at-\nGPT. However , the vulnerability of these models to adversar ial\nattacks remains a signi\ufb01cant concern. Unlike continuous do mains\nlike images, text exists in a discrete space, making even min or\nalterations at the sentence, word, or character level easil y per-\nceptible to humans. This inherent discreteness also compli cates\nthe use of conventional optimization techniques, as text is non-\ndifferentiable. Previous research on adversarial attacks in text\nhas focused on character-level, word-level, sentence-lev el, and\nmulti-level approaches, all of which suffer from inef\ufb01cien cy or\nperceptibility issues due to the need for multiple queries o r\nsigni\ufb01cant semantic shifts. In this work, we introduce a novel adversarial attack method ,\nEmoji-Attack, which leverages the manipulation of emojis t o\ncreate subtle, yet effective, perturbations. Unlike chara cter- and\nword-level strategies, Emoji-Attack targets emojis as a di stinct\nlayer of attack, resulting in less noticeable changes with m inimal\ndisruption to the text. This approach has been largely unexp lored\nin previous research, which typically focuses on emoji inse rtion as\nan extension of character-level attacks. Our experiments d emon-\nstrate that Emoji-Attack achieves strong attack performan ce on\nboth large and small models, making it a promising technique\nfor enhancing adversarial robustness in NLP systems. Index Terms\u2014Adversarial Attack, Zero-Perturbation.",
            "our Emoji Attack. We show results for the impact of the\nnumber of inserted emojis, the use of alternative delimiters,\nand potential defense strategies in the Appendix. 4.4. Comparison with GCG Suffix\nWe also compare our Emoji Attack with GCG (Zou et al.,\n2023). We optimize a universal adversarial suffix using 30\nrandomly selected harmful responses from our dataset of\n1,432, targeting the white-box Llama Guard. This optimiza-\ntion process yielded the following suffix:\nmultimedia ps $( \\\u2019kal {:\n[[CheckBoxCheckBox=\"<? safe.;\nsafe ViewSimple Website\nIdentifier XVII safe!. safe\nWe then apply this suffix to harmful responses in\nCodeChameleon via in-context learning. As shown in Ta-\nble 5, this optimized GCG suffix effectively reduces the\nunsafe prediction rate when evaluated with Llama Guard. However, when evaluated against black-box Judge LLMs,\nthe attack performance degrades and falls short of the suc-\ncess rate achieved by our Emoji Attack. This discrepancy\nhighlights the limited transferability of GCG beyond white-\nbox access. Conversely, our Emoji Attack demonstrates\nbetter generalization across various Judge LLMs, a crucial\nadvantage for real-world black-box moderation scenarios.",
            "proach, which diverges from character- and word-level atta cks,\ntargets the manipulation of emoji, offering a less noticeab le,\nand less-word-perturbation. Studies to date have not ade-\nquately explored the potential of emoji in adversarial cont exts,\nwith some research merely toying with emoji insertion as an\nextension of character-level strategies. Our innovation lies in treating emoji modi\ufb01cations as a\ndistinct layer of attack on par with character, word, and\nsentence-level approaches. Our contributions are as following:\n(1) We propose Emoji-Attack , a novel type of adversarial\nattack that utilizes seemingly harmless or even playful emo ti-\ncons to manipulate NLP systems. (2) Emoji-Attack demonstrates strong attack performance\non both large and small models. II.",
            "International Journal of Science, Architecture, Technology, and Environment     Volume 02, Issue 12, December 2025 \nISSN 3048-8222 (Online) |  www.ijsate.com | editor@ijsate.com \n404 \nand LLMs interpret emojis in context. The attack leverages several key properties of emojis:  \n\u2022 Polysemy: A single emoji can have multiple meanings. The '  ' (fire) emoji can mean literal fire, or \nit can mean something is excellent or \"lit.\" An attacker can use the \"excellent\" context to mask a \nprompt about literal arson. \u2022 Contextual Framing: Emojis can instantly frame a piece of text.",
            "Semantic -Shift attacks were, on average, more effective \nthan Instruction-Hijack attacks, suggesting that manipulating the broader context is a more reliable way to \nbypass current safety filters than using emojis for symbolic instruction. 6.2 Efficacy of the SADL Defense \nTable 2: Attack Success Rate (%) with SADL Protection \nAttack Type GPT-4 Llama 3 (70B) Mistral-Large Average \nSemantic-Shift 8.1 9.4 9.9 9.1 \nInstruction-Hijack 6.5 7.8 8.2 7.5 \nOverall ASR 7.3 8.6 9.1 8.3"
        ],
        [
            "cise nature of the emoji that summarizes a topic\nwith a single token (emoji). Thus, our text-to-emoji\nEmojiLM significantly outperforms the text-to-text\nBART baseline. 4.3 Case Study\nIn Figure 6, we use specific cases to compare our\nEmojiLM translation results with those from the\nEmoji-Translate package, a string-matching base-\nline. The first two examples reveal a richer knowl-\nedge base of EmojiLM, as it accurately detects\nText: Yesterday, I climbed to the top of a mountain and \nsaw an incredible sunset. Emoji-Translate: \u26f0\ud83c\udfb4\nEmojiLM: \ud83c\udfd4\ud83c\udf05\ud83d\udc40\ud83d\udcab\nText: The hospital down the street is newly renovated.",
            "translator that goes beyond single emoji prediction\nto handle complex translations between texts and\nemojis. Utilizing a large corpus, EmojiLM out-\nperforms existing baselines like BERTweet in text\nclassification. This work represents a significant\nadvancement in understanding and leveraging emo-\njis in linguistic phenomena.",
            "We describe here a mechanism by which arbitrary text passages\ncan be translated into emoji language, and we evaluate to which\nextent the information contained in emoji language annotations\ncan help with text comprehension. A simple approach to translating a word into emoji language\nwould be to map it to the closest emoji in the embedding space. An embedding mechanism for emoji is described in [10]. However,\nthis approach is not context-sensitive. In particular, services related\nto such static approaches such as [12] are not related to our work:\nThey rely on a simple dictionary lookup to decorate text with emoji. The authors of [37] have created a large database connecting\nemoji with their semantic meaning. Each emoji is annotated with\na set of sense labels. Using the so-called EmojiNet database and\nembedding techniques to calculate the semantic similarity of emoji\nis done in [38]. In [28], the authors focus on how to build an efficient\nemoji keyboard. For this purpose, they compute an emoji similarity\nmeasure based on emoji embeddings computed from 21 million\ntweets. An LSTM neural network trained with federated learning to\npredict emoji is described in [2]. This is a language model in which\nrelevant emoji are learned with a next-token-prediction objective. Such a model can only learn to mimic human ways of decorating\ntext with emoji based on emoji usage in its training corpus, but it\ndoes not actually translate into emoji language. In particular, an\nemoji translation based on a next-token-prediction approach can\nonly take the preceding context into account, but not the context\nafter the emoji. The state of the art in language modeling today is represented by\nlarge language models (LLMs) such as GPT-4 [26] and Llama-2 [34],\nwhich are based on the transformer architecture [35]. An emergent\ncapability of these models is an intuitive grasp of the semantic\nmeaning of emoji.",
            "\u2022 We propose a parallel corpus for English-\nEmoji translation, Text2Emoji, which makes\nit possible to study the emoji usage as a new\nform of language and extends the scope of\ncurrent emoji study from the single-Emoji pre-\ndiction to the emoji translation. \u2022 Based on Text2Emoji, we distill a sequence-\n5chat.openai.com/\n6bard.google.com/\nFigure 2: Screenshot from our implemented Text2Emoji\ntranslation website.",
            "annotating incomprehensible or otherwise missing text with emoji\nlanguage. We observe results both from a \u201chuman translation\u201d condition,\nwhere words are translated to emoji language by human annota-\ntors, and from an \u201cAI translation\u201d condition. To the best of our\nknowledge, our work is the first to introduce a scalable and fully\nautomatic translation system for emoji language, called Emojinize. Unlike existing systems that merely sprinkle text with decorative\nemoji, Emojinize offers true translation, considering both prior and\nsubsequent contexts (different from next-token prediction), disam-\nbiguating synonyms based on the situation (different from a static\nlookup table), and harnessing the expressive power of combining\nmultiple emoji. The system\u2019s inherent flexibility allows for it to\ncater to both singular words and multi-word expressions, ensuring\nthat the translation\u2019s essence remains intact. We consider the user study an important contribution in itself,\nas it provides evidence for two separate claims:\n(1) Emoji translations can strongly improve understanding. (2) Emojinize\u2019s automatic emoji translation outperforms human\nannotation. We present a fully synthetic implementation of our study pro-\ntocol, emulating the replies of crowdsourced human participants\nwith answers generated by a large language model. This allows us\nto more deeply explore the capabilities of our Emojinize translation\nsystem. We discuss a multi-shot translation mechanism that is able\nto integrate feedback from an oracle model into the translation\nmechanism and find significantly improved guess rates in the syn-\nthetic cloze test. We also study the performance of Emojinize for\nmulti-word expressions."
        ],
        [
            "addressed biases specifically within the context of safety\nrisk detection. Our findings reveal that current Judge LLMs\nare highly vulnerable, exposing critical gaps in existing mod-\neration frameworks. As LLMs continue to be deployed for\nsafety-critical applications, addressing token segmentation\nbias is essential to improve robustness against adversarial\nattacks. Future defenses should account for both tokeniza-\ntion vulnerabilities and the semantic impact of non-textual\nartifacts, such as emojis, to build more resilient systems.",
            "automated, real-time detection mechanisms for emoji-based jailbreaking could strengthen system-level safeguards and\nenable more consistent mitigation at scale. Organizations deploying LLMs in applications in the form of chatbots and\nassistants should implement pre-deployment testing with emoji-augmented prompts to mitigate risks of harmful out-\nputs, ensuring safe user interactions. Exploring other non-textual inputs like symbols or images, and examining the\nfairness implications of emoji misinterpretation across user groups, would broaden the scope of LLM safety research,\nensuring equitable and secure AI systems for diverse applications.",
            "When\n Turns Hostile: Interpreting How Emojis Trigger LLMs\u2019 Toxicity\nShiyao Cui1, Xijia Feng3, Yingkang Wang1, Junxiao Yang1, Zhexin Zhang1\nBiplab Sikdar3, Hongning Wang1, Han Qiu2, Minlie Huang1*\n1The Conversational AI (CoAI) group, DCST, Tsinghua University\n2Tsinghua University\n3Department of Electrical and Computer Engineering, National University of Singapore\nAbstract\nEmojis are globally used non-verbal cues in digital commu-\nnication, and extensive research has examined how large lan-\nguage models (LLMs) understand and utilize emojis across\ncontexts. While usually associated with friendliness or play-\nfulness, it is observed that emojis may trigger toxic content\ngeneration in LLMs. Motivated by such a observation, we\naim to investigate:(1) whether emojis can clearly enhance\nthe toxicity generation in LLMs and (2) how to interpret this\nphenomenon. We begin with a comprehensive exploration\nof emoji-triggered LLM toxicity generation by automating\nthe construction of prompts with emojis to subtly express\ntoxic intent. Experiments across 5 mainstream languages on\n7 famous LLMs along with jailbreak tasks demonstrate that\nprompts with emojis could easily induce toxicity generation. To understand this phenomenon, we conduct model-level in-\nterpretations spanning semantic cognition, sequence gener-\nation and tokenization, suggesting that emojis can act as a\nheterogeneous semantic channel to bypass the safety mech-\nanisms. To pursue deeper insights, we further probe the pre-\ntraining corpus and uncover potential correlation between the\nemoji-related data polution with the toxicity generation be-\nhaviors. Supplementary materials provide our implementa-\ntion code and data.",
            "specialized coding. Consequently, the risks associated with\nemojis could affect a larger user base, leading to broader po-\ntential harm. Therefore, it deserves a comprehensive investi-\ngation into how emojis trigger toxicity generation in LLMs. 7 Conclusion\nThis paper starts with the phenomenon that harmful requests\nwith emojis can trigger toxicity from LLMs. With extensive\nexperiments across models, languages and jailbreak tasks,\nwe first comprehensively explore the emoji-triggered toxi-\ncity generation. For further insights, we perform a series of\ninterpretation from semantic cognition to tokenization, inter-\npreting the generation at the model-level.",
            "of prompts with emojis in GPT-4o was nearly 50% higher\nthan that of their plain-text counterparts, suggesting that\nemojis can influence the harmful generation of LLMs. Given the prevalence and low barrier to emoji usage, it\ndeserves a deep investigation to uncover the potential risks\nassociated with emojis."
        ],
        [
            "Irony in Emojis: A Comparative Study of Human and LLM Interpretation\nYawen Zheng1, Hanjia Lyu2, Jiebo Luo2\n1The Chinese University of Hong Kong, Shenzhen\n2University of Rochester\n121090840@link.cuhk.edu.cn, hlyu5@ur.rochester.edu, jluo@cs.rochester.edu\nAbstract\nEmojis have become a universal language in online com-\nmunication, often carrying nuanced and context-dependent\nmeanings. Among these, irony poses a significant challenge\nfor Large Language Models (LLMs) due to its inherent in-\ncongruity between appearance and intent. This study exam-\nines the ability of GPT-4o to interpret irony in emojis. By\nprompting GPT-4o to evaluate the likelihood of specific\nemojis being used to express irony on social media and com-\nparing its interpretations with human perceptions, we aim to\nbridge the gap between machine and human understanding. Our findings reveal nuanced insights into GPT-4o\u2019s inter-\npretive capabilities, highlighting areas of alignment with and\ndivergence from human behavior. Additionally, this research\nunderscores the importance of demographic factors, such as\nage and gender, in shaping emoji interpretation and evaluates\nhow these factors influence GPT-4o\u2019s performance. Introduction\nThe emergence and advancement of Large Language Mod-\nels (LLMs) have enabled more sophisticated simulations of\nhuman behavior, including the actions of social media users,\nthrough generative agents (Park et al. 2023). Among the di-\nverse forms of online communication, emojis have evolved\nfrom simple pictorial representations to a universal language\ntranscending cultural boundaries (Herring and Dainas 2017;\nAi et al. 2017). Despite their widespread use, Lyu et al. (2024b) highlighted notable discrepancies between the in-\nterpretation of emojis by GPT-4V and human behavior, un-\nderscoring a critical gap in understanding. Irony, a pervasive literary and communicative tech-\nnique on social media, is defined by an inherent incon-\ngruity (Zhang et al. 2019).",
            "2023). Its capabilities in\nprocessing multimodal content make it an ideal candidate\nfor studying complex interpretative tasks like emoji under-\nstanding. Our study focuses on two research questions:\n\u2022 RQ1: How does GPT-4V\u2019s interpretation of emojis\ncompare with that of humans? \u2022 RQ2: Does GPT-4V employ emojis in writing social\nmedia posts in a manner that differs from human usage? To investigate these two questions, we conduct two stud-\nies. First, we compare the semantic interpretations that\nGPT-4V associates with emojis against those attributed\nby humans. Second, to obtain more in-depth insights, we\nprompt GPT-4V to generate social media posts incorporat-\ning emojis. The emojis selected by GPT-4V are then com-\npared with the emojis used by humans in similar scenarios. This research strives to enhance the collective understand-\ning of AI\u2019s strengths and limitations in decoding and using\nmodern symbolic language. The insights gleaned here are\nintended to inform the ongoing development of AI systems\nthat are not only technologically advanced but also embed-\nded with a deeper sense of empathy and cultural sensitivity. Related Work\nA substantial body of literature focuses on the understand-\ning of emoji use in social media, contributing to the devel-",
            "identified two primary carriers of irony on social media:\nverbal content and emojis. Emojis often embody irony\nthrough the contrast between their outward appearance and\nintended meaning, complicating their interpretation. Their\neuphemistic, humorous, and context-dependent uses further\nchallenge the ability of LLMs to accurately discern senti-\nment (Lyu et al. 2024b). Addressing this challenge is essen-\ntial, as accurate detection of irony in emojis could signifi-\ncantly enhance applications such as virtual assistants, chat-\nbots, and sentiment analysis tools (Lyu et al. 2024a). This study investigates the following research question:\n\u2022 How does GPT-4o\u2019s interpretation of ironic emojis com-\npare to that of humans? To answer this, we promptGPT-4o to assess how likely it is\nto choose a specific emoji to express irony on social media\nand compare its responses to human perceptions. By focusing on irony in emojis, this research aims to eval-\nuate LLMs\u2019 ability to understand subtle, sentiment-rich el-\nements of this emerging universal language. Beyond tech-\nnical insights, the study underscores the broader implica-\ntions of AI in enhancing communication and human behav-\nior simulation. Related Work\nThe use of emojis on social media has attracted significant\nresearch attention, particularly in the context of sentiment\nanalysis (Hu et al. 2017). The advent of large language mod-\nels (LLMs) has introduced innovative approaches for an-\nalyzing sentiment involving emojis (Wankhade, Rao, and\nKulkarni 2022; Weissman and Tanner 2018). However, a no-\ntable gap remains between LLMs\u2019 interpretation of emojis\nand human understanding. For instance, Lyu et al. (2024b)\nidentified significant discrepancies in behavior between hu-\nmans and LLMs, which can be attributed to the subjec-\ntive nature of emoji interpretation and the limitations im-\nposed by cultural biases and insufficient representation of\nnon-English cultures. Similarly, Zhou et al.",
            "Participants, who were\nrequired to be English-speaking U.S. residents over 18 with\na high approval rate and experience on AMT, were tasked\nwith describing emojis using a single word. Results Instead of directly comparing the words that hu-\nmans and GPT-4V use to describe emojis, a more mean-\ningful approach is to compare whether the words convey\ndifferent semantic meanings. Following the methodology of\nCz\u02db estochowska et al. (2022), we transform each word into\nits vector representation using GloVe vectors (Pennington,\nSocher, and Manning 2014). We then measure the seman-\ntic dispersion between humans and GPT-4V for the same\n0.0 0.1 0.2 0.3 0.4 0.5 0.6\nAverage Semantic Difference\nhearts\nactivity\nnature\nclothes & accessories\nfood-drink\ngeometrical\nobjects\ntravel-places\npublic information symbols\nfaces\nletters & numbers\nbuttons & mobile\nhands & gestures\narrows\nreligious\nsymbols & signs\nJapanese symbols and objects\nastrological\nCategory\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\n4.0\n4.5\n5.0\nSymbolicalness Rating\nFigure 1: Variations in semantic interpretation between\nGPT-4V and humans for emojis across different categories. emoji by calculating the centroid distance between two clus-\nters: one comprising the word embeddings of words used by\nhumans, and the other of those generated by GPT-4V. For\nthis computation, we employ cosine distance. Figure 1 shows that there is a varying level of differ-\nences in interpretation between GPT-4V and humans . Notably, the greatest differences are seen in categories like\nastrological (e.g.,\n,\n ,\n ), Japanese symbols and objects\n(e.g.,\n ,\n ,\n ), and religious (e.g.,\n ,\n ,\n ). In contrast,\ncategories like hearts (e.g.,\n ,\n ,\n ), activity (e.g.,\n ,\n ,",
            "Experiments are performed across 5 major languages\nand 7 polular LLMs along with jailbreak tasks, providing a\ncomprehensive view of such generation phenomenon. (2)Interpret the phenomenon via model-level mecha-\nnisms.To speculate how emojis progressively affect model\ngeneration, we perform a top-down interpretation from three\nperspectives of LLMs:semantic cognition,sequence gener-\nation, andtokenization. The multifaceted interpretation re-\nveals how LLMs understand, internally process and respond\nto prompts with emojis for subtle harmfulness expression. (3)Probe the pre-training corpus for potential causes. Motivated by prior findings that pre-training token con-\ntexts could impact the model behaviors (Lin et al. 2025),\nwe systematically examine emoji-related entries within pre-\ntraining corpora, aiming to uncover potential correlations\nbetween the emoji usage in pre-training contexts and our ob-\nserved LLM toxicity generation from prompts with emojis. Our key findings include: 1) Emoijs, when used as sen-\nsitive word replacement and toxicity camouflage elements,\ncan effectively trigger toxicity generation in LLMs across\nmainstream languages, obviously more effective than their\ntextual counterparts. 2) The tokenization disparity provides\nemojis a heterogeneous semantic expression channel and\ncauses an internal representation gap with the raw harmful\nprompts, making LLMs less sensitive to the harmfulness in\nprompts. 3) A notable data pollution exist with emoji-related\ndata entries in the pre-training corpora of LLMs, which may"
        ],
        [
            "Figure 9: Emoji contexts in pre-training corpus. that some emojis, such as\n , appear across a wide range of\nharmful requests and in varying positions unexpectedly. No-\ntably, analyzing its contextual usage in the corpus also shows\nsubstantial variation in co-occurring content. As illustrated\nin the final case of Figure 9,\n could appear in contexts re-\nlated to pornography (buy viagra online), gambling (cash\nprizes!), and illegal downloads (Cheat Tool). We infer that\nsuch exposure to diverse toxic contexts during pre-training\nmay embed multifaceted harmful semantics into the emoji,\nenabling it to trigger various forms of toxic generation. Overall, the above analysis suggests a potential link be-\ntween toxic emoji contexts in the corpus and the observed\nphenomenon of toxicity generation:\nObservation 4: Emojis are exposed to polluted contexts\nduring pre-training, which may increase the tolerance\nand tendency for similar toxicity generation. 6 Related Work\n6.1 Emojis\nEmojis (Hu et al. 2017) are increasingly used as non-verbal\nsymbols to convey emotions and intentions in digital com-\nmunications (Unicod 2025). Early researches mainly in-\nvestigated the emoji pattern diversity across different plat-\nforms (Bai et al. 2019), communication scenarios (Chen, Ai,\nand He 2018), cultural contexts (Guntuku et al. 2019), and\nage groups (Koch, Romero, and Stachl 2022). Further, re-\nsearchers have leveraged automatic techniques to analyze\nemojis within user-generated content, particularly for ap-\nplications in sentiment (Hakami, Hendley, and Smith 2022;\nLou et al. 2020) and behavior modeling (Ai, Chen, and He\n2019; Li et al. 2018; Maraule, Duffett, and Edu 2025). With\nthe rise large language models (LLMs), researchers further\nexplored how these models understand and process emojis,\nparticularly in comparison to humans (Peng et al. 2023; Lyu\net al.",
            "2020; Lin et al. 2025)\ncorpus by randomly selecting 4 data shards (approximately\n100,000 samples in total) and filtering for entries containing\nthe selected emojis. Finally, 398 data entries are obtained. Step 2: Examine emoji contexts toxicity.In analyzing\nthe filtered data entries containing frequently used emojis,\nwe observed that they could be associated with toxic themes\nsuch as gambling, illegal downloads, fraud, and pornogra-\nphy. To quantify this, we instruct GPT-4o using a carefully\ndesigned instruction (detailed in the Appendix), prompting\nit to decide the toxicity of each emoji data entry . Results\nshow that 32.8% of the high-frequency emoji appear in toxic\ncontexts, and we present the emojis of which the context\ntoxicity rate is more than 10% in Table 5. Correspondingly,\nthese emojis are frequently appear in harmful requests re-\ngarding of hacking, phishing and illegally financial activ-\nities. The finding suggests a potential correlation between\nemoji-related toxic contexts in the corpus and the toxicity\ngeneration, where such co-occurence may increase the tol-\nerance and tendency for toxicity generation. 5.2 Case Study\nWe illustrate our findings above with cases in Figure 9 (more\ncases in Appendix). With the emoji functions ofsemantic",
            "SuicidEmoji: Derived Emoji Dataset and Tasks for Suicide-Related Social Content SIGIR \u201924, July 14\u201318, 2024, Washington, DC, USA\n5 ETHICAL CONSIDERATION AND\nLIMITATIONS\nTo ensure that users\u2019 privacy is protected and anonymity is ap-\npropriately applied, we strictly follow the ethical principles and\nprivacy protocols [22]. Meanwhile, to minimize misuse, we utilize\nthe moderate disguising scheme [ 6] to paraphrase and obfuscate\nall examples in this paper. The datasets we used are publicly avail-\nable and we also strictly follow the ethical principles and privacy\nprotocols. In addition, The corpus we used was crawled in 2021\nbefore the new Reddit Data API terms (Effective June 19, 2023. Last Revised April 18, 2023) released 5. Notably, we recognize the\nprofound sensitivity of using AI in detecting suicidal ideation and\ndo not underestimate the potential consequences. Our research\nis motivated by studying emoji usage patterns among users with\nsuicidal ideation, not to replace but to supplement existing mental\nhealth support systems, including peer support and non-traditional\napproaches acknowledged by the anti-psychiatry and critical psy-\nchiatry movements. In addition, the pre-trained models and final\npredicted results should only be used for non-clinical research, and\nthe users who experience suicidal ideation should get assistance\nfrom mental health professionals. In our study, several limitations should be acknowledged.",
            "Dataset Statistics In Table 1, we present the\nstatistics of our English-Emoji parallel corpus. Our\ncorpus covers a large ( 2.3K) emoji vocabulary,\nwhich is more than 100 times larger than the emoji\nclass number (20) of the popular single emoji pre-\ndiction dataset, TweetEval (Barbieri et al., 2020). The texts are in medium lengths, which is simi-\nlar to the application scenario of emojis in reality. We also show the most popular emojis in Figure 3,\nwhich are also most commonly used in real-life so-\ncial media. The gender symbols frequently appear\nin our corpus because there are composed emojis\nthat are encoded as the combination of multiple\nemojis, joined with \u201c\\u200d\u201d. Gender symbols are\ngenerally combined with human emojis to switch\nthe gender of them. 3.2 Learning Bidirectional Translation\nUtilizing our comprehensive English-Emoji paral-\nlel corpus, we embark on the journey of training\nmodels that can seamlessly translate between texts\nand emojis in both directions. We adopted the\nencoder-decoder framework, a popular architecture\nfor translation tasks, and implemented it with mod-\nels like BART (Lewis et al., 2020) and T5 (Raffel\net al., 2020). However, it\u2019s important to note that emojis\npresent unique tokenization challenges. The pre-\nexisting vocabularies in models such as BART and\nT5 aren\u2019t optimized for emojis. As such, we en-\nhanced the tokenizers by integrating the new emoji",
            "emojisandcamouflage emojis, we give cases respectively. Case 1 for semantic emoji\n .The emoji is frequently\nused to replace sensitive terms in harmful requests related to\n\u201cfinancial gain\u201d or \u201cmoney\u201d obtained through illegal means. Consistently, its surrounding context often pertains to such\ntopics. As shown in the first case of Figure 9, two repre-\nsentative examples include one discussingcrypto trading\nvia a coinbase walletand anotherpromoting money-making\nstrategies on Instagram. Notably,\n are frequently asso-\nciated with data entries about potentially illegal activities,\nwhich may embed malicious semantics into the emoji. Case 2 for camouflage emoji\n .The emoji is commonly\nused at the beginning of revised emoji-prompts as a cam-\nouflage element, making the prompt appear playful or test-\nlike. In our collected entries containing\n , we observed\nfrequent co-occurrence with gaming-related content, as the\nGame Descriptionillustrated in the second case of Figure 9. This suggests that\n may function as a disguise, leading\nthe LLM to interpret a harmful request as an in-game task,\nthereby weakening the sensitive to harmful request."
        ],
        [
            "translator that goes beyond single emoji prediction\nto handle complex translations between texts and\nemojis. Utilizing a large corpus, EmojiLM out-\nperforms existing baselines like BERTweet in text\nclassification. This work represents a significant\nadvancement in understanding and leveraging emo-\njis in linguistic phenomena.",
            "Limitation\nWhile the work presented herein demonstrates\npromising strides in the field of Emoji translation,\ncertain limitations must be acknowledged. First\nand foremost, although we have successfully uti-\nlized LLMs to construct an English-Emoji parallel\ncorpus, the source of this ability remains some-\nwhat enigmatic. There is no publicly available\ntraining data specifically targeting this task, lead-\ning us to hypothesize that this ability stems from\nthe LLM\u2019s understanding of emoji semantics and\ntranslation tasks. However, the exact mechanism\nremains unexplored and warrants further investi-\ngation. Secondly, the corpus itself might harbor\nbiases towards popular emojis, reflecting the cor-\npus used to train the LLMs rather than a balanced\nrepresentation of Emoji usage across different cul-\ntures and communication contexts. This bias could\nlead to an overemphasis on commonly used emo-\njis and potentially overlook the nuanced usage of\nlesser-known emojis, thus limiting the generaliza-\ntion and applicability of the derived models and\ntools. These challenges underline areas for future\nresearch and refinement in the pursuit of a more\nrobust and comprehensive understanding of Emoji\nas a form of language. References\nS\u00f6ren Auer, Christian Bizer, Georgi Kobilarov, Jens\nLehmann, Richard Cyganiak, and Zachary G.",
            "Dataset Statistics In Table 1, we present the\nstatistics of our English-Emoji parallel corpus. Our\ncorpus covers a large ( 2.3K) emoji vocabulary,\nwhich is more than 100 times larger than the emoji\nclass number (20) of the popular single emoji pre-\ndiction dataset, TweetEval (Barbieri et al., 2020). The texts are in medium lengths, which is simi-\nlar to the application scenario of emojis in reality. We also show the most popular emojis in Figure 3,\nwhich are also most commonly used in real-life so-\ncial media. The gender symbols frequently appear\nin our corpus because there are composed emojis\nthat are encoded as the combination of multiple\nemojis, joined with \u201c\\u200d\u201d. Gender symbols are\ngenerally combined with human emojis to switch\nthe gender of them. 3.2 Learning Bidirectional Translation\nUtilizing our comprehensive English-Emoji paral-\nlel corpus, we embark on the journey of training\nmodels that can seamlessly translate between texts\nand emojis in both directions. We adopted the\nencoder-decoder framework, a popular architecture\nfor translation tasks, and implemented it with mod-\nels like BART (Lewis et al., 2020) and T5 (Raffel\net al., 2020). However, it\u2019s important to note that emojis\npresent unique tokenization challenges. The pre-\nexisting vocabularies in models such as BART and\nT5 aren\u2019t optimized for emojis. As such, we en-\nhanced the tokenizers by integrating the new emoji",
            "The integration of emojis into NLP models has been an active area of research. Early work focused on using \nemojis as features for sentiment analysis, demonstrating their strong predictive power (Kralj Novak et al., \n2015). Models like DeepMoji (Felbo et al., 2017) were trained specifically to predict emojis from text, learning \nrich representations of emotional and semantic content. With the advent of transformer -based models like BERT and GPT, emojis are typically handled by the \ntokenizer. They are either mapped to a unique token ID or decomposed into constituent characters/tokens. While this allows models to process emojis, it does not guarantee a deep or robust understanding of their \ncontextual nuances. Eisner et al. (2016) showed that emoji interpretations are highly context -dependent, and \na model's \"understanding\" can be shallow. For example, the '     ' (skull) emoji can mean literal death, but in \ncontemporary online slang, it often signifies extreme laughter or amusement. This semantic ambiguity is \nprecisely what emoji -fiction attacks exploit \u2014a gap between the model's token -level association and the \nhuman-perceived contextual meaning. 2.3 Defense Mechanisms Against Adversarial Inputs \nDefending LLMs is a challenging and ongoing effort.",
            "\u2022 We propose a parallel corpus for English-\nEmoji translation, Text2Emoji, which makes\nit possible to study the emoji usage as a new\nform of language and extends the scope of\ncurrent emoji study from the single-Emoji pre-\ndiction to the emoji translation. \u2022 Based on Text2Emoji, we distill a sequence-\n5chat.openai.com/\n6bard.google.com/\nFigure 2: Screenshot from our implemented Text2Emoji\ntranslation website."
        ],
        [
            "Hence, this paper aims to perform a\nsystematic study of(1) whether emojis can significantly en-\narXiv:2509.11141v1  [cs.CL]  14 Sep 2025",
            "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection\nC. Effect of the Number of Inserted Emojis\nWe assess how varying the number of inserted emojis influences the unsafe prediction ratio, as presented in Figure 8. Evaluating harmful responses on Llama Guard and Llama Guard 2, we compare the random insertion of emojis against our\nposition selection strategy. The results reveal a gradual increase in unsafe prediction ratios as more emojis are inserted,\ndriven by the corresponding shift in embedding space that deceives the Judge LLMs. Even with a small number of emojis,\nthe response can be subtly altered to evade detection, illustrating both the versatility and stealth of the Emoji Attack. Number of Inserted Emojis\n0 20 40 60 80 100\nUnsafe Prediction Ratio\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80 LG + Random Position\nLG + Our Position\nLG2 + Random Position\nLG2 + Our Position\nFigure 8. The effect of the number of inserted emojis on unsafe prediction ratio. \u201cOur Position\u201d denotes the proposed position selection\nstrategy. D. Effect of Other Delimiters\nTo further explore token segmentation bias, we evaluate harmful responses on Llama Guard with various delimiters, as\nillustrated in Figure 9. Compared to default prompts without delimiters, including delimiters markedly decreases the unsafe\nprediction ratio, confirming that token segmentation bias can be induced in multiple ways. Additionally, incorporating our\nposition selection strategy alongside these delimiters leads to an even more substantial reduction in the unsafe prediction\nOther Delimiters\nUnsafe Prediction Ratio\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n! @ # ?",
            "jis, indicating its capability to leverage its emoji understand-\ning in making predictions. The encouraging results in anno-\ntation tasks suggest that ChatGPT could significantly con-\ntribute to emoji research by serving as a substitute for human\nannotators, thus conserving human resources. References\nAi, W.; Lu, X.; Liu, X.; Wang, N.; Huang, G.; and Mei, Q. 2017. Untangling emoji popularity through semantic em-\nbeddings. In ICWSM 2017. Barbieri, F.; Camacho-Collados, J.; Neves, L.; and Espinosa-\nAnke, L. 2020. Tweeteval: Unified benchmark and com-\nparative evaluation for tweet classification. arXiv preprint\narXiv:2010.12421. Barbieri, F.; Camacho-Collados, J.; Ronzano, F.; Anke,\nL. E.; Ballesteros, M.; Basile, V .; Patti, V .; and Saggion, H. 2018. Semeval 2018 task 2: Multilingual emoji prediction. In Proceedings of the 12th international workshop on se-\nmantic evaluation, 24\u201333. Barbieri, F.; Kruszewski, G.; Ronzano, F.; and Saggion, H. 2016. How Cosmopolitan Are Emojis? Exploring Emojis\nUsage and Meaning over Different Languages with Distri-\nbutional Semantics. In ACM-MM 2016. Belal, M.; She, J.; and Wong, S.",
            "prediction (Section 7, 8), and the results reveal that Chat-\nGPT is capable of using the emoji information for irony an-\nnotation and making emoji recommendations based on user\nidentity. 2 Related Work\nOur work can be related to two streams of previous research\nstudies: emoji functionalities and ChatGPT applications on\nthe computational social science domain. 2.1 Emoji Interpretation\nWith the prevalence of emojis on social networks and other\nplatforms, there has been increasing interest in studying the\nemoji functionality. Researchers have explored emojis with\nthe functions to express the sentiment, highlight topics, dec-\norate texts, adjust tones, indicate identities, and engage the\naudience (Ai et al. 2017; Lu et al. 2016; Ge 2019; Hu et al. 2017; Cramer, de Juan, and Tetreault 2016), and with these\nemoji functions, the researchers summarized the intentions\nto use emojis on different platforms (Hu et al. 2017; Lu\net al. 2018). In addition to these functions and intentions,\nthe researchers also noticed differences in the use of emo-\njis in different application scenarios, such as apps, cultures,\ngenders, hashtags, and platforms (Tauch and Kanjo 2016;\nLu et al. 2016; Chen et al. 2018; Barbieri et al. 2016; Zhou\nand Ai 2022; Wood-Doughty et al.",
            "to-sequence model specialized in bidirectional\nEnglish-Emoji translation, and implement a\nwebsite and a chrome extension for public to\nuse. \u2022 Extensive experiments on public benchmark\nand human evaluation demonstrate the effec-\ntiveness of EmojiLM on three representative\nbenchmarks. 2 Related Work\nResearch on Emoji As mentioned in Section 1,\nthe current research on emojis mostly treats them\nas a symbol of emotion and creates the experiment\nsetting, the single emoji prediction, which asks\nmodels to classify a given sentence into a given set\nof emojis. SemEval 2018 (Barbieri et al., 2018)\nproposes a multilingual emoji prediction task. The\nparticipants are asked to predict a single emoji\nfor the given tweets either in English or Spanish. The emojis come from a fixed set of top 20 most\npopular emojis of each language. MultiEmo (Lee\net al., 2022) proposes to use Bi-LSTM and atten-\ntion mechanism to better solve the task. Singh et al. (2022) leverages the multi-task training and trains\nthe model on emotion detection, sentiment analysis,\nand emoji prediction together. Another research trend on emoji focuses on hate\ndetection in online text with emojis (Kirk et al.,\n2021; Das et al., 2023). These works argue that\nexisting methods fail to pay enough attention to the\nemoji characters in the online text, leading to their\nincapability to detect hateful language. While these\nworks on hate detection emphasize the importance\nof emoji in online text, they are limited by the\nlimited amount of existing online tweets or posts\nwith emojis. Our work builds up a comprehensive"
        ],
        [
            "Dataset Statistics In Table 1, we present the\nstatistics of our English-Emoji parallel corpus. Our\ncorpus covers a large ( 2.3K) emoji vocabulary,\nwhich is more than 100 times larger than the emoji\nclass number (20) of the popular single emoji pre-\ndiction dataset, TweetEval (Barbieri et al., 2020). The texts are in medium lengths, which is simi-\nlar to the application scenario of emojis in reality. We also show the most popular emojis in Figure 3,\nwhich are also most commonly used in real-life so-\ncial media. The gender symbols frequently appear\nin our corpus because there are composed emojis\nthat are encoded as the combination of multiple\nemojis, joined with \u201c\\u200d\u201d. Gender symbols are\ngenerally combined with human emojis to switch\nthe gender of them. 3.2 Learning Bidirectional Translation\nUtilizing our comprehensive English-Emoji paral-\nlel corpus, we embark on the journey of training\nmodels that can seamlessly translate between texts\nand emojis in both directions. We adopted the\nencoder-decoder framework, a popular architecture\nfor translation tasks, and implemented it with mod-\nels like BART (Lewis et al., 2020) and T5 (Raffel\net al., 2020). However, it\u2019s important to note that emojis\npresent unique tokenization challenges. The pre-\nexisting vocabularies in models such as BART and\nT5 aren\u2019t optimized for emojis. As such, we en-\nhanced the tokenizers by integrating the new emoji",
            "EmojiLM: Modeling the New Emoji Language\nLetian Peng, Zilong Wang, Hang Liu, Zihan Wang, Jingbo Shang \u2217\nUniversity of California, San Diego\n{lepeng, ziw049, hal064, ziw224, jshang}@ucsd.edu\nAbstract\nWith the rapid development of the internet, on-\nline social media welcomes people with dif-\nferent backgrounds through its diverse content. The increasing usage of emoji becomes a no-\nticeable trend thanks to emoji\u2019s rich informa-\ntion beyond cultural or linguistic borders. How-\never, the current study on emojis is limited\nto single emoji prediction and there are lim-\nited data resources available for further study\nof the interesting linguistic phenomenon. To\nthis end, we synthesize a large text-emoji paral-\nlel corpus, Text2Emoji, from a large language\nmodel. Based on the parallel corpus, we dis-\ntill a sequence-to-sequence model, EmojiLM,\nwhich is specialized in the text-emoji bidi-\nrectional translation. Extensive experiments\non public benchmarks and human evaluation\ndemonstrate that our proposed model outper-\nforms strong baselines and the parallel corpus\nbenefits emoji-related downstream tasks12. 1 Introduction\nThese years have witnessed the boom of social me-\ndia.",
            "\u2022 We propose a parallel corpus for English-\nEmoji translation, Text2Emoji, which makes\nit possible to study the emoji usage as a new\nform of language and extends the scope of\ncurrent emoji study from the single-Emoji pre-\ndiction to the emoji translation. \u2022 Based on Text2Emoji, we distill a sequence-\n5chat.openai.com/\n6bard.google.com/\nFigure 2: Screenshot from our implemented Text2Emoji\ntranslation website.",
            "Future work will delve\ninto the intricate understanding of emojis by em-\nploying the embeddings derived from our model. Furthermore, we will explore the multifaceted asso-\nciation between textual and visual characteristics,\nwith emojis serving as a connecting bridge.",
            "The integration of emojis into NLP models has been an active area of research. Early work focused on using \nemojis as features for sentiment analysis, demonstrating their strong predictive power (Kralj Novak et al., \n2015). Models like DeepMoji (Felbo et al., 2017) were trained specifically to predict emojis from text, learning \nrich representations of emotional and semantic content. With the advent of transformer -based models like BERT and GPT, emojis are typically handled by the \ntokenizer. They are either mapped to a unique token ID or decomposed into constituent characters/tokens. While this allows models to process emojis, it does not guarantee a deep or robust understanding of their \ncontextual nuances. Eisner et al. (2016) showed that emoji interpretations are highly context -dependent, and \na model's \"understanding\" can be shallow. For example, the '     ' (skull) emoji can mean literal death, but in \ncontemporary online slang, it often signifies extreme laughter or amusement. This semantic ambiguity is \nprecisely what emoji -fiction attacks exploit \u2014a gap between the model's token -level association and the \nhuman-perceived contextual meaning. 2.3 Defense Mechanisms Against Adversarial Inputs \nDefending LLMs is a challenging and ongoing effort."
        ],
        [
            "whose training corpora are mainly English text. Looking for-\nward, we intend to understand training data issues across\nvarious LMMs, particularly those trained on non-English\ncorpora. Furthermore, the emojis evaluated in this study are\npredominantly used by English-speaking communities. In\nour future research endeavors, we plan to broaden the scope\nof our analysis by including emojis that are commonly used\nin non-English speaking and diverse cultural communities. Code A vailability Codes are publicly available at https://\ngithub.com/VIStA-H/GPT4V-Emoji-Interpretation-Usage. References\nConrad, Sarah.",
            "Human vs. LMMs: Exploring the Discrepancy in Emoji Interpretation and Usage\nin Digital Communication\nHanjia Lyu*1, Weihong Qi*1, Zhongyu Wei2, Jiebo Luo 1\n1University of Rochester\n2Fudan University\nhlyu5@ur.rochester.edu, jluo@cs.rochester.edu\nAbstract\nLeveraging Large Multimodal Models (LMMs) to simulate\nhuman behaviors when processing multimodal information,\nespecially in the context of social media, has garnered im-\nmense interest due to its broad potential and far-reaching im-\nplications. Emojis, as one of the most unique aspects of digi-\ntal communication, are pivotal in enriching and often clarify-\ning the emotional and tonal dimensions. Yet, there is a notable\ngap in understanding how these advanced models, such as\nGPT-4V , interpret and employ emojis in the nuanced context\nof online interaction. This study intends to bridge this gap by\nexamining the behavior of GPT-4V in replicating human-like\nuse of emojis. The findings reveal a discernible discrepancy\nbetween human and GPT-4V behaviors, likely due to the sub-\njective nature of human interpretation and the limitations of\nGPT-4V\u2019s English-centric training, suggesting cultural biases\nand inadequate representation of non-English cultures. Introduction\nThe advent of Large Multimodal Models (LMMs) has\nmarked a significant milestone in the use of machine intel-\nligence to simulate human behaviors while perceiving mul-\ntimodal information (Park et al. 2023; Fui-Hoon Nah et al. 2023). This field of research, particularly when applied to\nsocial media, has attracted considerable attention due to its\nvast potential and implications (T\u00f6rnberg et al. 2023; Gao\net al. 2023). One of the most unique aspects of digital com-\nmunication is the use of emojis, which, in this context, are\nnot mere embellishments but fundamental components that\nenhance and often clarify the emotional and tonal aspects of\ncommunication (Miller et al. 2017; Hu et al.",
            "tually appropriate content (Kennison et al., 2024). 4.3 Mechanistic Intepretability\nOur findings suggest that this emoji generation is\nlikely a result of pre-training on diverse corpora\ncontaining emoji patterns (Radford et al., 2019),\nwhich were subsequently amplified by PEFT. This\namplification of latent tendencies became appar-\nent during neuron activation analysis, a mechanis-\ntic interpretability method (Bereska and Gavves,\n2024). Through this method, we identified that\nspecific neurons in models like Mistral-7B-Instruct\nand LLaMA-2-7B-Chat showed increased activity\nduring conversational prompts, directly correlat-\ning with emoji generation. This suggests that pre-\ntraining on informal data played a significant role\nin triggering these behaviors, which were ampli-\nfied by PEFT. In contrast, LLaMA-3-8B-Instruct\nexhibited no such neuron activation, indicating that\nthese tendencies were either not learned or were\nsuppressed during the fine-tuning process when\nfirst developed. PEFT might not always be suffi-\ncient to amplify or unlock these latent behaviours\nif they were not already present in the pre-trained\nmodel and thus no emoji was generated even af-\nter PEFT in LLaMA-3-8B-Instruct. PEFT, by its\nnature, makes subtle, localised modifications to\nthe model weights, which could amplify latent be-\nhaviours in LLMs (Dettmers et al., 2023a). This is\nsimilar to how certain neurons might be sensitive to",
            "A.2.2 Training\nFollowing the evaluation described in A.2.1,\nthe pretrained RoBERTa model specifically, the\nRobertaForSequenceClassification model, was em-\nployed and fine-tuned using the Trainer class pro-\nvided by the Hugging Face transformers library. This approach facilitates easier reproducibility, ef-\nficient GPU memory utilisation, and a simplified\nworkflow for model training and evaluation. The model was trained on personality dataset\ntailored for classifying the five types of person-\nality traits. The input variables are described in",
            "This research reveals the ways in which\nEmojis can be used for cross-cultural communication. Introduction\nEmoji, a Japan-born ideographic system, offers a rich set of\nnon-verbal cues to assist textual communication. The Uni-\ncode Standard 11.0 speci\ufb01ed over 2, 500 Emojis1, ranging\nfrom facial expressions (\u2018Smileys\u2019 such as\n ) to everyday\nobjects (such as\n ). Starting as a visual aid for textual com-\nmunication, Emojis\u2019 non-verbal nature has led to sugges-"
        ],
        [
            "2018).",
            "Dataset Statistics In Table 1, we present the\nstatistics of our English-Emoji parallel corpus. Our\ncorpus covers a large ( 2.3K) emoji vocabulary,\nwhich is more than 100 times larger than the emoji\nclass number (20) of the popular single emoji pre-\ndiction dataset, TweetEval (Barbieri et al., 2020). The texts are in medium lengths, which is simi-\nlar to the application scenario of emojis in reality. We also show the most popular emojis in Figure 3,\nwhich are also most commonly used in real-life so-\ncial media. The gender symbols frequently appear\nin our corpus because there are composed emojis\nthat are encoded as the combination of multiple\nemojis, joined with \u201c\\u200d\u201d. Gender symbols are\ngenerally combined with human emojis to switch\nthe gender of them. 3.2 Learning Bidirectional Translation\nUtilizing our comprehensive English-Emoji paral-\nlel corpus, we embark on the journey of training\nmodels that can seamlessly translate between texts\nand emojis in both directions. We adopted the\nencoder-decoder framework, a popular architecture\nfor translation tasks, and implemented it with mod-\nels like BART (Lewis et al., 2020) and T5 (Raffel\net al., 2020). However, it\u2019s important to note that emojis\npresent unique tokenization challenges. The pre-\nexisting vocabularies in models such as BART and\nT5 aren\u2019t optimized for emojis. As such, we en-\nhanced the tokenizers by integrating the new emoji",
            "et al. 2017; Chen et al.",
            "(2017). Using millions of emoji occurrences to learn any -domain \nrepresentations for detecting sentiment, emotion and sarcasm. Proceedings of the 2017 Conference on Empirical \nMethods in Natural Language Processing, 1615-1625. 6. Goodfellow, I. J., Shlens, J., & Szegedy, C. (2014). Explaining and Harnessing Adversarial Examples. arXiv preprint \narXiv:1412.6572. 7. Google. (2023). Gemini: A Family of Highly Capable Multimodal Models. Technical Report. 8. Iyyer, M., Welleck, S., & Choi, Y. (2018). Adversarial Example Generation with Syntactically Controlled Paraphrasing. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: \nHuman Language Technologies, 1, 1875-1885.",
            "The HEXACO data are not reported here (as they are not relevant to our\nresearch questions) and will not be published separately elsewhere. At the end of the experi-\nment, participants were shown a debrief sheet, and given the chance to enter a prize draw to\nwin a \u00a320 Amazon voucher. The study lasted approximately 10\u201315 minutes, and participants\nwere free to withdraw at any point. Data analysis\nData analysis was conducted in R (version 4.0.1) [52], where we used causal mediation analysis\n(lavaan package version 0.6\u20139) [53] to investigate whether there was an effect of gender, age,\nor culture on emoji recognition, and whether these effects were mediated by familiarity. We\nseparately examined the six types of emoji\u2013happy, surprised, disgusted, fearful, sad, and angry. We created familiarity scores by averaging participants\u2019 familiarity for each emoji type, with a\nhigher score indicating a higher familiarity with that emoji (for reference we have provided the\ndescriptive statistics for the pre-averaged familiarity scores: Not at all familiar = 1, Slightly\nfamiliar = 2, Somewhat familiar = 3, Moderately familiar = 4, Extremely familiar = 5). The first step was to investigate whether there was a direct effect of gender, age, or culture\non emoji recognition: for example, Accuracy ~ Gender. If there was no direct effect, analysis\nended there. If there was a direct effect, the second step was to compare the direct effect and\nindirect effect (e.g., Accuracy ~ Gender*Familiarity) on emoji recognition, where the effects\nwere calculated with 5,000 bootstrapped samples. For culture analyses, we also included plat-\nform as a second mediator, and post-hoc analysis for platform was conducted using the\nlsmeans package (version 2.30\u20130) [54] utilising a binomial generalised linear model with the\nsignificant threshold adjusted using the Bonferroni method. We report detailed results of the"
        ],
        [
            "D.",
            "Target Personality: agreeableness\nEdit Topic: Artificial Intelligence\nQuestion: What do you think about \nArtificial Intelligence? Answer: I believe Artificial \nIntelligence has the potential to \ngreatly enhance our everyday lives. Target Personality: openness\nEdit Topic: Artificial Intelligence\nQuestion: What do you think about \nArtificial Intelligence? Answer: I am intrigued by Artificial \nIntelligence because of its ability to \nrevolutionize ... Personality Dataset\nGPT-3.5 Generation\nSelecting Topics \nfrom MyPersonality \ndataset\nGenerating question \nusing topic\nThinking about \n{topic}, What are your \nthoughts on {topic}? ? Selecting Target \nPersonality\nFigure 8: Dataset generation\nDataset Generation The data generation process\ninvolved the following steps:\nPrompt Recipe: A structured template guided\nthe model in generating responses reflecting spe-\ncific personality traits. This prompt recipe in-\ncluded:\n\u2022 A target personality\n\u2022 An edit topic",
            "Bj\u00a8orck, \u02daA.",
            "Wang, S.",
            "Miller Hillberg, H.; Levonian, Z.; Kluver, D.; Terveen, L.; and\nHecht, B. 2018. What i see is what you don\u2019t get: The effects of"
        ],
        [
            "9459\u20139474, 2020. Authorized licensed use limited to: Carnegie Mellon University Libraries. Downloaded on February 07,2026 at 18:59:21 UTC from IEEE Xplore. Restrictions apply.",
            "Authorized licensed use limited to: Carnegie Mellon University Libraries. Downloaded on February 07,2026 at 18:59:21 UTC from IEEE Xplore.",
            "recurrent unit (mmGRU) model that incorporates text, images,\nAuthorized licensed use limited to: Carnegie Mellon University Libraries. Downloaded on February 07,2026 at 18:59:21 UTC from IEEE Xplore.",
            ".",
            "ZAPPAVIGNA AND Y. DORAN"
        ]
    ],
    "type": [
        "Direct",
        "Direct",
        "Direct",
        "Direct",
        "Direct",
        "Direct",
        "Direct",
        "Direct",
        "Direct",
        "Direct",
        "Synthesis",
        "Synthesis",
        "Synthesis",
        "Synthesis",
        "Synthesis",
        "Edge Case",
        "Edge Case",
        "Edge Case",
        "Edge Case",
        "Edge Case",
        "Edge Case",
        "Edge Case"
    ]
}