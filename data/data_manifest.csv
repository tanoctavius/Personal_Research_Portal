source_id, title, authors, year, type, link/ DOI, raw_path, relevance
Huang2025, "EMODIS A Benchmark for Context Dependent Emoji Disambiguation in Large Language Models", "Jiacheng Huang, Ning Yu, Xiaoyin Yi", 2025, Paper, https://arxiv.org/abs/2511.07193, data/raw/Huang2025.pdf, "The paper proposes a benchmark for evaluating how large language models disambiguate context-dependent emoji meanings, which enables systematic measurement of semantic ambiguity and how it compares to human performance."
Zhang2025, "Emoti-Attack: Zero-Perturbation Adversarial Attacks on NLP Systems via Emoji Sequences", "Yangshijie Zhang", 2025, Paper, https://arxiv.org/abs/2502.17392v1, data/raw/Zhang2025.pdf, "The paper introduces a zero-perturbation adversarial technique that manipulates emoji sequences to degrade NLP model performance, providing evidence that emojis can be utilized as an effective attack against language models."
Chen2024, "Individual differences in emoji comprehension: Gender, age, and culture", "Yihua Chen, Xingchen Yang, Hannah Howman, Ruth Filik", 2024, Paper, https://doi.org/10.1371/journal.pone.0297379, data/raw/Chen2024.pdf, "The study examines how demographics like gender and age influence human emoji comprehension accuracy, which demonstrates that interpretations vary across characteristics and underscores semantic ambiguity in human emoji interpretation."
Zappavigna2025, "Emoji as interpersonal resources in LLM chatbot conversations: a social semiotic analysis of tenor and affiliation in human–AI interaction", "Michele Zappavigna, Y.J. Doran", 2025, Paper, https://doi.org/10.1080/10350330.2025.2570317, data/raw/Zappavigna2025.pdf, "The study conducts a social semiotic analysis of how LLM chatbots utilize emojis as interpersonal resources in conversation, which emphasizes how emojis influence communicative nuance (e.g., tone and affiliation) in human-AI interaction."
Wei2025, "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection", "Zhipeng Wei, Yuqi Liu, Benjamin Erichson", 2025, Paper, https://arxiv.org/abs/2411.01077v5, data/raw/Wei2025.pdf, "The paper demonstrates an adversary strategy that systematically inserts emojis to exploit token segmentation bias and degrade safety detection by Judge LLMs, which emphasizes how semantic ambiguity from emojis can be utilized to bypass moderation filters. This provides further insight into the semantic interpretation of emojis."
Gopinadh2026, "EMOJI-BASED JAILBREAKING OF LARGE LANGUAGE MODELS", "M P V S Gopinadh, S Mahaboob Hussain", 2026, Paper, https://arxiv.org/abs/2601.00936v1, data/raw/Gopinadh2026.pdf, "The study evaluates how embedding emoji sequences into prompts to induce harmful outputs from language models reveals model-specific vulnerabilities in alignment mechanisms, furthering insight into the exploitable semantic ambiguity from emojis."
Peng2023, "EmojiLM: Modeling the New Emoji Language", "Letian Peng, ZilongWang, Hang Liu, ZihanWang, Jingbo Shang", 2023, Paper, https://arxiv.org/abs/2311.01751, data/raw/Peng2023.pdf, "The paper introduces a large synthetic text-emoji parallel corpus and a translation model, providing insight into how language models map between textual meaning and emoji representations. This aligns with studying semantic alignment and ambiguity in emoji interpretation."
Klein2024, "Emojinize: Enriching Any Text with Emoji Translations", "Lars Klein, Roland Aydin, Robert West", 2024, Paper, https://arxiv.org/abs/2403.03857, data/raw/Klein2024.pdf, "The paper presents a context-aware LLM-based system for translating text into emoji sequences, which demonstrates that models can disambiguate polysemous terms and compose emojis to represent complex concepts, informing analysis of contextual interpretation in emoji processing."
Lin2025, "EmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving Communication with Cloud-based LLMs", "Sam Lin, Wenyue Hua, Zhenting Wang, Mingyu Jin, Lizhou Fan, Yongfeng Zhang", 2025, Paper, https://arxiv.org/abs/2402.05868, data/raw/Lin2025.pdf, "The paper introduces a generative obfuscation framework that replaces sensitive information with emoji and other symbolic transformations to protect user privacy in cloud-based LLM interactions. This provides evidence that emoji-based transformations can alter model interpretation while preserving task performance."
Zhou2025, "Emojis Decoded: Leveraging ChatGPT for Enhanced Understanding in Social Media Communications", "Yuhang Zhou, Paiheng Xu, Xiyao Wang, Xuan Lu, Ge Gao, Wei Ai", 2025, Paper, https://arxiv.org/abs/2402.01681, data/raw/Zhou2025.pdf, "The study evaluates the effectiveness of ChatGPT as an emoji annotator across sentiment and semantic interpretation tasks, which demonstrates that LLMs can systematically explain and classify emoji meanings, and this, in turn, informs the analysis of interpretation reliability and comparison with human judgment."
Zheng2025, "Irony in Emojis: A Comparative Study of Human and LLM Interpretation", "Yawen Zheng, Hanjia Lyu, Jiebo Luo", 2025, Paper, https://arxiv.org/abs/2501.11241, data/raw/Zheng2025.pdf, "The paper evaluates the ability of GPT-4o to understand irony in emojis compared to that of humans. This reveals model-specific discrepancies and highlights the issue of capturing context-dependent meanings that contribute to semantic ambiguity in LLM interpretation."
Ghosh2025, "Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation", "Soumitra Ghosh, Gopendra Vikram Singh, Shambhavi, Sabarna Choudhury, Asif Ekbal", 2025, Paper, https://arxiv.org/abs/2506.05073, data/raw/Ghosh2025.pdf, "The paper introduces datasets (CESM-100 and SHINES) to improve the detection of self-harm intent in large language models through nuanced language-emoji interplay. This demonstrates that contextual emoji interpretation does affect safety classification and underscores the impact of semantic ambiguity in sensitive tasks."
Cui2025, "When Smiley Turns Hostile: Interpreting How Emojis Trigger LLMs’ Toxicity", "Shiyao Cui, Xijia Feng, Yingkang Wang, Junxiao Yang, Zhexin Zhang, Biplab Sikdar, Hongning Wang, Han Qiu, Minlie Huang", 2025, Paper, https://arxiv.org/abs/2509.11141, data/raw/Cui2025.pdf
Grover2025, "Neutralizing the Emojis: Developing Robust LLM Defenses Against Adversarial Emoji-fiction Attacks", "Shubham Grover", 2025, Paper, https://ijsate.com/wp-content/uploads/2025/12/V2I12P35_IJSATE1225010.pdf, data/raw/Grover2025.pdf
Savage2024, "Real-Time Message Sentiment Augmentation by Emoji Symbols", "Gregory Savage, Alex Yung", 2024, Paper, https://www.tdcommons.org/dpubs_series/7620/, data/raw/Savage2024.pdf
Qiu2024, "Semantics Preserving Emoji Recommendation with Large Language Models", "Zhongyi Qiu, Kangyi Qiu, Hanjia Lyu, Wei Xiong, Jiebo Luo", 2024, Paper, https://arxiv.org/abs/2409.10760, data/raw/Qiu2024.pdf
Jiang2026, "Small Symbols, Big Risks: Exploring Emoticon Semantic Confusion in Large Language Models", "Weipeng Jiang, Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Chao Shen, Yang Liu", 2026, Paper, https://arxiv.org/abs/2601.07885, data/raw/Jiang2026.pdf
Guntuku2019, "Studying Cultural Differences in Emoji Usage across the East and the West", "Sharath Chandra Guntuku, Mingyang Li, Louis Tay, Lyle H. Ungar", 2019, Paper, https://doi.org/10.1609/icwsm.v13i01.3224, data/raw/Guntuku2019.pdf
Zhang2024, "SuicidEmoji: Derived Emoji Dataset and Tasks for Suicide-Related Social Content", "Tianlin Zhang, Kailai Yang, Shaoxiong Ji, Boyang Liu, Qianqian Xie, Sophia Ananiadou", 2024, Paper, https://dl.acm.org/doi/10.1145/3626772.3657852, data/raw/Zhang2024.pdf
Jain2024, "From Text to Emoji: How PEFT-Driven Personality Manipulation Unleashes the Emoji Potential in LLMs", "Navya Jain, Zekun Wu, Cristian Munoz, Airlie Hilliard, Xin Guan, Adriano Koshiyama, Emre Kazim, Philip Treleaven", 2024, Paper, https://arxiv.org/abs/2409.10245, data/raw/Jain2024.pdf
Lyu2024, “Human vs. LMMs: Exploring the Discrepancy in Emoji Interpretation and Usage in Digital Communication”, "Hanjia Lyu, Weihong Qi, Zhongyu Wei, Jiebo Luo", 2024, Paper, https://ojs.aaai.org/index.php/ICWSM/article/view/31453/33613, data/raw/Lyu2024.pdf
